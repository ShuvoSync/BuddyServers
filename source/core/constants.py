from shutil import rmtree, copytree, copy, ignore_patterns, move, disk_usage, which
from concurrent.futures import ThreadPoolExecutor
from urllib.parse import quote, unquote, urlparse
from typing import TYPE_CHECKING, Any, Optional
from email.utils import parsedate_to_datetime
from random import randrange, choices
from datetime import datetime as dt
from difflib import SequenceMatcher
from xml.etree import ElementTree
from bs4 import BeautifulSoup
from copy import deepcopy
from pathlib import Path
from typing import final
from munch import Munch
import multiprocessing
from glob import glob
from nbt import nbt
import cloudscraper
import unicodedata
import subprocess
import threading
import traceback
import platform
import requests
import tarfile
import zipfile
import hashlib
import string
import psutil
import socket
import shlex
import stat
import time
import json
import sys
import os
import re

if TYPE_CHECKING:
    from argparse import ArgumentParser
    import source.core as core
    import source.ui as ui
    from kivy.uix.widget import Widget


# ---------------------------------------------- Global Variables ------------------------------------------------------

text_logo = [
    r"  ____            _     _       ____                                     ",
    r" |  _ \          | |   | |     / ___|                                    ",
    r" | |_) |_   _  __| | __| |_   _\___ \ ___ _ ____   _____ _ __ ___        ",
    r" |  _ <| | | |/ _` |/ _` | | | |___) / _ \ '__\ \ / / _ \ '__/ __|       ",
    r" | |_) | |_| | (_| | (_| | |_| |___) |  __/ |   \ V /  __/ |  \__ \       ",
    r" |____/ \__,_|\__,_|\__,_|\__, |____/ \___|_|    \_/ \___|_|  |___/      ",
    r"                           __/ |                                         ",
    r"                          |___/                                          ",
]

app_title = "BuddyServers"
app_version = "2.3.5"

buddyscript_version = "1.5.1"
telepath_version = "1.2"

# Various project URLs for additional functionality within the app
project_repo:           str = "https://github.com/ShuvoSync/BuddyServers"
ci_artifacts:           str = "https://cloud.buddyservers.com"
website:                str = "https://buddyservers.com"


# True if the application is compiled as a Pyinstaller executable
app_compiled:          bool = getattr(sys, 'frozen', False)

# Stores launch parameters globally, and the configurable options are below
boot_arguments: 'ArgumentParser' = None

# Set to True to add full verbosity with logging
# Also changes some UI functions like the ability to force crashes for testing
debug:                 bool = False

# Set to True to launch with the CLI interface from 'source.ui.headless'
headless:              bool = False

# Allows the warning which prevents the UI from opening to be dismissed
bypass_admin_warning:  bool = False

# List of server names to automatically launch after the UI loads
boot_launches:    list[str] = []



# Determine operating system
os_name = 'windows' if os.name == 'nt' else \
          'macos' if platform.system().lower() == 'darwin' else \
          'linux' if os.name == 'posix' else \
          os.name



# Global application paths
@final
class paths:

    # Execution folder & assets folder
    executable_folder:    str = getattr(sys, "_MEIPASS", str(Path(sys.executable).resolve().parent)) if app_compiled \
                                else os.path.abspath(os.curdir)

    build_data:           str = os.path.join(executable_folder, 'build-data.json')
    ui_assets:            str = os.path.join(executable_folder, "ui", "assets")
    locales:              str = os.path.join(ui_assets, 'locales.json')


    # User directories and app folder
    user_home:            str = os.path.expanduser('~')
    user_downloads:       str = os.path.join(user_home, 'Downloads')

    appdata:              str = os.getenv("APPDATA") if os_name == 'windows' \
                                else f'{user_home}/Library/Application Support' if os_name == 'macos' \
                                else user_home

    minecraft_saves:      str = os.path.join(appdata, '.minecraft', 'saves') if os_name != 'macos' \
                                else f"{user_home}/Library/Application Support/minecraft/saves"


    # App-specific root directories
    app_folder:           str = os.path.join(appdata, ('.buddyservers' if os_name != 'macos' else 'BuddyServers'))
    servers:              str = os.path.join(app_folder, 'Servers')
    config:               str = os.path.join(app_folder, 'Config')
    tools:                str = os.path.join(app_folder, 'Tools')
    logs:                 str = os.path.join(app_folder, 'Logs')
    backups:              str = os.path.join(app_folder, 'Backups')
    downloads:            str = os.path.join(app_folder, 'Downloads')
    uploads:              str = os.path.join(app_folder, 'Uploads')
    temp:                 str = os.path.join(app_folder, 'Temp')
    cache:                str = os.path.join(app_folder, 'Cache')
    tmpsvr:               str = os.path.join(temp, 'tmpsvr')
    os_temp:              str = os.getenv("TEMP") if os_name == "windows" else "/tmp"


    # Tools-specific directories
    scripts:              str = os.path.join(tools, 'buddyscript')
    templates:            str = os.path.join(tools, 'templates')
    java:                 str = os.path.join(tools, 'java')
    playit:               str = os.path.join(tools, 'playit')
    telepath:             str = os.path.join(tools, 'telepath')
    telepath_servers:     str = os.path.join(telepath, 'telepath-servers.json')
    telepath_secrets:     str = os.path.join(telepath, 'telepath-secrets')
    telepath_script_temp: str = os.path.join(scripts, 'telepath-temp')


    # Filesystem location of the current executable
    launch_path:          str = None

    # Filesystem location of bundled utilities from 'build-tools'
    bundled_utils:        str = os.path.join(
        os.path.abspath(executable_folder if app_compiled else os.path.join(executable_folder, '..', 'build-tools')),
        'utils'
    )



# For '*.bat' or '*.sh' script names respectively
start_script_name = "Start"

# Filename of the BuddyServers server config file
server_ini        = 'buddyservers.ini'  if os_name == "windows" else '.buddyservers.ini'

# Filename of the temporary command list for automatic execution on server start
command_tmp       = 'start-cmd.tmp' if os_name == "windows" else '.start-cmd.tmp'

# Image file extension whitelist
valid_image_formats = [
    "*.png", "*.jpg", "*.jpeg", "*.gif", "*.jpe", "*.jfif",
    "*.tif", "*.tiff", "*.bmp", "*.icns", "*.ico", "*.webp"
]

# Config file extension whitelist
valid_config_formats = [
    'properties', 'yml', 'yaml', 'tml', 'toml', 'json',
    'json5', 'ini', 'txt', 'snbt'
]



# --------------------------------------------- General Functions ------------------------------------------------------

# Log wrapper
def send_log(object_data, message, level=None, *a):
    try: from source.core import logger
    except: return
    return logger.send_log(f'{__name__}.{object_data}', message, level, 'core')



# ---------------------------------------- Operating System Operations -------------------------------------------------
# <editor-fold desc="Operating System Operations">

# Username of the user who launched BuddyServers
username:    str = None

# Hostname of the computer that launched BuddyServers
hostname:    str = None

# Total system memory as an integer (GB)
total_ram:   int = round(psutil.virtual_memory().total / 1073741824)

# Maximum BuddyServers memory usage limit (75% of total system memory)
max_memory:  int = int(round(total_ram - (total_ram / 4)))

# Check if this instance is running in Docker
def check_docker() -> bool:
    global is_docker
    if os_name == 'linux':
        if 'Alpine' in run_proc('uname -v', True, log_only_in_debug=True).strip():
            is_docker = True; return is_docker

    cgroup = Path('/proc/self/cgroup')
    docker_check = Path('/.dockerenv').is_file() or cgroup.is_file() and 'docker' in cgroup.read_text()
    if docker_check: send_log('check_docker', f'{app_title} is running inside a Docker container')

    is_docker = docker_check
    return docker_check
is_docker:  bool = None

# Check if system architecture is ARM-based
def check_arm() -> bool:
    global is_arm
    command = 'echo %PROCESSOR_ARCHITECTURE%' if os_name == 'windows' else 'uname -m'
    arch = run_proc(command, True, log_only_in_debug=True).strip()
    arm_check = arch in ['aarch64', 'arm64']
    is_arm = arm_check
    return arm_check
is_arm:     bool = None

# Check if system is running this instance with Rosetta translation
def check_rosetta() -> bool:
    global is_rosetta
    if os_name == 'macos':
        try: is_rosetta = run_proc("/usr/sbin/sysctl -n sysctl.proc_translated", True, log_only_in_debug=True).strip() == '1'
        except : pass
is_rosetta: bool = None

# Check if the running user has admin/root rights
# Flag ensures it only logs the first time it's executed
def is_admin() -> bool:
    global admin_check_logged
    try:

        # Admin check on Windows
        if os_name == 'windows':
            import ctypes
            elevated = ctypes.windll.shell32.IsUserAnAdmin() == 1

        # Root user check on Unix-based systems
        else: elevated = os.getuid() == 0

    # If this check fails, it's not running as admin
    except:   elevated = False


    # Log startup permissions (this only needs to be logged once, but is checked multiple times)
    if not admin_check_logged:
        if elevated: send_log('is_admin', f'{app_title} is running with admin-level permissions', 'warning')
        else:        send_log('is_admin', f'{app_title} is running with user-level permissions')
        admin_check_logged = True

    return elevated
admin_check_logged: bool = False

# Returns False if less than 15GB free
def check_free_space(telepath_data: dict = None, required_free_space: int = 15) -> bool:
    if telepath_data:
        try:
            return str(api_manager.request(
                endpoint = '/main/check_free_space',
                host = telepath_data['host'],
                port = telepath_data['port']
            )).lower() == 'true'
        except:
            return False

    # Resolve true location of app folder past symlinks
    try:    real_dir = os.fspath(Path(paths.app_folder).resolve(strict=False))
    except: real_dir = paths.app_folder

    free_space = round(disk_usage(real_dir).free / 1048576)
    enough_space = free_space > 1024 * required_free_space
    action = 'has enough' if enough_space else 'does not have enough'
    send_log('check_free_space', f'primary disk {action} free space: {round(free_space/1024, 2)} GB / {required_free_space} GB', None if enough_space else 'error')
    return enough_space


# Replacement for os.system to prevent CMD flashing, and also for debug logging
def run_proc(cmd: str, return_text=False, log_only_in_debug=False, success_code=0) -> str or int:
    std_setting = subprocess.PIPE

    result = subprocess.run(
        cmd,
        shell  = True,
        stdout = std_setting,
        stderr = std_setting,
        text   = True,
        errors = 'ignore'
    )

    output = result.stdout or result.stderr or ''
    return_code = result.returncode
    run_content = f'\n{output.strip()}'
    log_content = f'with output:{run_content}' if run_content.strip() else 'with no output'

    if return_code != success_code and (debug or not log_only_in_debug):
        send_log('run_proc', f"'{cmd}': returned exit code {result.returncode} {log_content}", 'error')
    else:
        send_log('run_proc', f"'{cmd}': returned exit code {result.returncode} {log_content}")

    return output if return_text else return_code


# Spawns a detached process with new process group
def run_detached(script_path: str):
    send_log('run_detached', f"executing '{script_path}'...")

    # Build a minimal environment
    clean_env = os.environ.copy()

    # Remove direct _MEIPASS and both PYI prefixes
    for k in tuple(clean_env):
        if k in ("_MEIPASS", "PYTHONHOME", "PYTHONPATH") or k.startswith(("PYI_", "_PYI_")):
            clean_env.pop(k, None)

    # Remove any pair whose value still points into an old _MEI* dir
    for k, v in tuple(clean_env.items()):
        if isinstance(v, str) and "_MEI" in v:
            clean_env.pop(k, None)

    # For LD_LIBRARY, prefer *_ORIG if present, else unset entirely
    for var in ("LD_LIBRARY_PATH", "DYLD_LIBRARY_PATH"):
        orig = clean_env.pop(f"{var}_ORIG", None)
        if orig is not None: clean_env[var] = orig
        else:                clean_env.pop(var, None)


    if os_name == 'windows':
        return subprocess.Popen(
            ['cmd', '/c', script_path],
            stdout = subprocess.DEVNULL,
            stderr = subprocess.DEVNULL,
            stdin = subprocess.DEVNULL,
            creationflags = 0x00000008,
            close_fds = True,
            env = clean_env
        )

    # macOS & Linux
    os.chmod(script_path, stat.S_IRWXU)
    args = ['bash', script_path]
    if os_name != 'macos': args.insert(0, 'setsid')
    subprocess.Popen(
        args,
        stdout = subprocess.DEVNULL,
        stderr = subprocess.DEVNULL,
        stdin = subprocess.DEVNULL,
        start_new_session = True,
        close_fds = True,
        env = clean_env
    )


# Create folder if it doesn't exist
def folder_check(directory: str):
    if not os.path.exists(directory):
        try:
            os.makedirs(directory)
            send_log('folder_check', f"Created '{directory}'")
        except FileExistsError:
            pass
    else:
        send_log('folder_check', f"'{directory}' already exists")


# Attempt to delete a directory tree without error
def safe_delete(directory: str) -> bool:
    global restart_flag

    if not directory:
        return False

    # Guard restart scripts and update log from deletion until restart
    if directory == paths.temp and restart_flag:
        return False

    try:
        if os.path.exists(directory):
            rmtree(directory)
            send_log('safe_delete', f"successfully deleted '{directory}'")

    except OSError as e:
        send_log('safe_delete', f"could not delete '{directory}': {e}", 'warning')

    return not os.path.exists(directory)


# Delete every '_MEIPASS' folder in case of leftover files, and delete '.buddyservers\Downloads' and '.buddyservers\Uploads'
def cleanup_old_files():
    global restart_flag

    send_log('cleanup_old_files', f"cleaning up old {app_title} temporary files in '{paths.os_temp}'")

    # macOS stores bundle in the .app, not temp
    if os_name != 'macos':
        for item in glob(os.path.join(paths.os_temp, "*")):

            # Only delete folders that are owned by BuddyServers, and that are not currently in use
            if (item != paths.executable_folder) and ("_MEI" in os.path.basename(item)):
                if os.path.exists(os.path.join(item, 'ui-assets', 'animations', 'loading_pickaxe.gif')):
                    try:
                        safe_delete(item)
                        send_log('cleanup_old_files', f"successfully deleted remnants of '{item}'")
                    except PermissionError:
                        pass

    safe_delete(os.path.join(paths.os_temp, '.kivy'))
    if not restart_flag:

        # Delete temporary files
        os.chdir(get_cwd())
        safe_delete(paths.downloads)
        safe_delete(paths.uploads)
        safe_delete(paths.temp)
        safe_delete(paths.telepath_script_temp)
        safe_delete(os.path.join(paths.ui_assets, 'live'))


# Extract archive
def extract_archive(archive_file: str, export_path: str, skip_root=False):
    archive = None
    archive_type = None

    send_log('extract_archive', f"extracting '{archive_file}' to '{export_path}'...")

    try:
        if archive_file.endswith("tar.gz"):
            archive = tarfile.open(archive_file, "r:gz")
            archive_type = "tar"
        elif archive_file.endswith("tar"):
            archive = tarfile.open(archive_file, "r:")
            archive_type = "tar"
        elif archive_file.endswith("zip") or archive_file.endswith("mrpack"):
            archive = zipfile.ZipFile(archive_file, 'r')
            archive_type = "zip"

        if archive and paths.app_folder in os.path.split(export_path)[0]:
            folder_check(export_path)

            # Use tar if available, for speed
            use_tar = False
            if archive_type == 'tar':
                try:
                    rc = subprocess.call(['tar', '--help'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                    use_tar = rc == 0

                except Exception as e:
                    send_log('extract_archive', f"failed to acquire 'tar' provider: {e}", 'warning')
                    use_tar = False


            # Log provider usage
            provider = 'tar' if use_tar else 'python'
            send_log('extract_archive', f"using '{provider}' as a provider")


            # Keep integrity of archive
            if not skip_root:

                if use_tar:
                    archive_file = os.path.abspath(archive_file)
                    run_proc(f"tar -xf \"{archive_file}\" -C \"{export_path}\"")
                else:
                    archive.extractall(export_path)

            # Export from root folder instead
            else:
                if use_tar:
                    run_proc(f"tar -x{'z' if archive_file.endswith('.tar.gz') else ''}f \"{archive_file}\" -C \"{export_path}\"")

                    # Find sub-folders
                    folders = [f for f in glob(os.path.join(export_path, '*')) if os.path.isdir(f)]
                    target = os.path.join(export_path, folders[0])

                    # Move data to root, and delete the sub-folder
                    for f in glob(os.path.join(target, '*')):
                        move(f, os.path.join(export_path, os.path.basename(f)))

                    safe_delete(target)

                elif archive_type == "tar":
                    def remove_root(file):
                        root_path = file.getmembers()[0].path
                        if "/" in root_path:
                            root_path = root_path.split("/", 1)[0]
                        root_path += "/"
                        l = len(root_path)

                        for member in file.getmembers():
                            if member.path.startswith(root_path):
                                member.path = member.path[l:]
                                yield member
                    archive.extractall(export_path, members=remove_root(archive))

                elif archive_type == "zip":
                    root_path = archive.namelist()[0]
                    for zip_info in archive.infolist():
                        if zip_info.filename[-1] == '/':
                            continue
                        zip_info.filename = zip_info.filename[len(root_path):]
                        archive.extract(zip_info, export_path)

            send_log('extract_archive', f"extracted '{archive_file}' to '{export_path}'")

        else: send_log('extract_archive', f"archive '{archive_file}' was not found", 'error')

    except Exception as e:
        send_log('extract_archive', f"error extracting '{archive_file}': {format_traceback(e)}", 'error')

    if archive:
        archive.close()


# Create an archive
def create_archive(file_path: str, export_path: str, archive_type='tar') -> str or None:
    file_name = os.path.basename(file_path)
    archive_name = f'{file_name}.{archive_type}'
    final_path = os.path.join(export_path, archive_name)

    send_log('create_archive', f"compressing '{file_path}' to '{export_path}'...")

    folder_check(export_path)

    # Create a .tar archive
    if archive_type == 'tar':
        try:
            rc = subprocess.call(['tar', '--help'], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
            use_tar = rc == 0

        except Exception as e:
            send_log('create_archive', f"failed to acquire 'tar' provider: {e}", 'warning')
            use_tar = False


        # Log provider usage
        provider = 'tar' if use_tar else 'python'
        send_log('create_archive', f"using '{provider}' as a provider")


        # Use tar command if available
        if use_tar:
            run_proc(f'tar -C \"{os.path.dirname(file_path)}\" -cvf \"{final_path}\" \"{file_name}\"')

        # Otherwise, use the Python implementation
        else:
            with tarfile.open(final_path, "w", compresslevel=6) as tar_file:
                # Use glob for when an asterisk is used
                for file in glob(file_path):
                    tar_file.add(file, os.path.basename(file))

    # Create a .zip archive
    elif archive_type == 'zip':
        with zipfile.ZipFile(final_path, "w", compresslevel=6) as zip_file:
            # Use glob for when an asterisk is used
            for file in glob(file_path):
                zip_file.write(file, os.path.basename(file))

    # Return file path if it exists
    if os.path.exists(final_path):
        send_log('create_archive', f"compressed '{file_path}' to '{export_path}'")
        return final_path

    else: send_log('create_archive', f"something went wrong compressing '{file_path}'", 'error')


# Check if root is a folder instead of files, and move sub-folders to destination
def move_files_root(source: str, destination: str = None):
    destination = source if not destination else destination
    folder_list = [d for d in glob(os.path.join(source, '*')) if os.path.isdir(d)]
    file_list = [f for f in glob(os.path.join(source, '*')) if os.path.isdir(f)]
    if len(folder_list) == 1 and len(file_list) <= 1:

        # Move data to root, and delete the sub-folder
        for f in glob(os.path.join(folder_list[0], '*')):
            move(f, os.path.join(destination, os.path.basename(f)))
        safe_delete(folder_list[0])

    # If destination is a different path and there is no root folder, move anyway
    elif source != destination:
        for f in glob(os.path.join(source, '*')):
            move(f, os.path.join(destination, os.path.basename(f)))


# Cross-platform function to copy a file or folder
# src_dir --> ../dst_dir/new_name
def copy_to(src_dir: str, dst_dir: str, new_name: str, overwrite=True) -> bool:
    final_path = os.path.join(dst_dir, new_name)
    item_type = "file" if os.path.isfile(src_dir) else "directory" if os.path.isdir(src_dir) else None
    success = False
    final_item = None

    # Check if src_dir is file or folder, and if dst_dir can be written to
    if os.path.exists(src_dir) and item_type:
        if (os.path.exists(final_path) and overwrite) or (not os.path.exists(final_path)):

            send_log('copy_to', f"copying '{os.path.basename(src_dir)}' to '{final_path}'...")
            folder_check(dst_dir)

            if item_type == "file":
                final_item = copy(src_dir, final_path)

            elif item_type == "directory":
                final_item = copytree(src_dir, final_path, dirs_exist_ok=True, ignore=ignore_patterns('*session.lock'))

            if final_item:
                success = True
                send_log('copy_to', f"successfully copied to '{new_name}'")

    if not success:
        send_log('copy_to', f"something went wrong copying to '{new_name}'", 'error')

    return success


# Retrieves the best-guess TTY device path to the terminal that launched it
def get_parent_tty() -> str or None:
    # Windows doesn't have a terminal
    if os_name == 'windows': return None

    # If there's a TTY in STDIO, just use that
    for fd in (1, 0, 2):
        try:
            if os.isatty(fd): return shlex.quote(os.ttyname(fd))
        except Exception: pass

    # On Linux, try '/proc/self/fd' symlinks
    if os_name == 'linux' and os.path.exists('/proc/self/fd'):
        for fd in (1, 0, 2):
            try:
                p = os.readlink(f'/proc/self/fd/{fd}')
                if p.startswith('/dev/'): return shlex.quote(p)
            except Exception: pass

    # If that doesn't work, ask 'ps' for TTY of this PID and walk up the process tree
    def _ps_col(pid: int, col: str):
        try:
            out = subprocess.check_output(['ps', '-o', f'{col}=', '-p', str(pid)], stderr=subprocess.DEVNULL, text=True).strip()
            if out: return shlex.quote(out)
            return None
        except Exception: return None

    def _ps_tty(pid: int):
        t = _ps_col(pid, 'tty')
        if t and t != '?' and t.lower() != 'ttys??':
            # ps returns like 'pts/3' or 'ttys002'
            return shlex.quote(t) if t.startswith('/dev/') else f'/dev/{t}'
        return None

    # Try current process and then a few ancestors
    pid = os.getpid()
    tty = _ps_tty(pid)
    if tty: return shlex.quote(tty)
    ppid_seen = set()
    ppid = os.getppid()

    # Don't walk indefinitely
    for _ in range(5):
        if not ppid or ppid in ppid_seen: break
        ppid_seen.add(ppid)
        tty = _ps_tty(ppid)
        if tty: return shlex.quote(tty)

        p = _ps_col(ppid, 'ppid')
        try: ppid = int(p) if p else None
        except Exception: ppid = None

    return None


# Glob to find hidden folders as well
def hidden_glob(path: str) -> list:

    home_shortcut = False
    if "~" in path:
        home_shortcut = True
        path = path.replace("~", paths.user_home)

    final_list = [item for item in glob(path + "*")]
    relative_dir = os.path.split(path)[0]
    try:
        final_list += [os.path.join(relative_dir, item) for item in os.listdir(relative_dir)
                       if item.startswith(".") and item.startswith(os.path.split(path)[0])]
    except OSError:
        pass

    if home_shortcut:
        final_list = [item.replace(paths.user_home, "~") for item in final_list]

    if paths.executable_folder in final_list:
        final_list.remove(paths.executable_folder)

    final_list = [item for item in final_list if item.startswith(path.replace(paths.user_home, "~") if home_shortcut else path)]

    final_list = sorted(final_list)
    return final_list


# Returns MD5 checksum of file
def get_checksum(file_path):
    return str(hashlib.md5(open(file_path, 'rb').read()).hexdigest())


# Get current directory, and revert to exec path if it doesn't exist
def get_cwd() -> str:
    # try: new_dir = os.path.abspath(os.curdir)
    # except: pass
    return paths.executable_folder


# Formats and returns the operating system as a string
def format_os() -> str:

    # System architecture (this app only supports 64-bit) ----------------------------
    arch_map = {
        "amd64": "64-bit", "x86_64": "64-bit",
        "aarch64": "ARM 64-bit", "arm64": "ARM 64-bit"
    }
    arch = arch_map.get(platform.machine().lower(), 'Unknown architecture')

    # Windows ------------------------------------------------------------------------
    def _windows_info() -> (str, str):
        data = platform.uname()
        product = data.system
        if 'server' in data.release.lower(): release = f'Server {data.release.lower().replace("server","").strip()}'
        else: release = data.release.strip()

        if '.' in data.version: build = data.version.rsplit('.')[-1]
        else: build = data.version.strip()

        return f'{product} {release}', build

    # macOS --------------------------------------------------------------------------
    def _mac_info() -> (str, str):
        version = None
        build = None
        for line in subprocess.check_output(["sw_vers"], text=True).strip().splitlines():
            if line.startswith('ProductVersion:'): version = line.split(':', 1)[-1].strip()
            if line.startswith('BuildVersion:'): build = line.split(':', 1)[-1].strip()

        if version: product = f'macOS {version}'
        else: product = 'macOS'

        return product, build

    # Linux --------------------------------------------------------------------------
    def _linux_info() -> (str, str):
        distro_name = None
        distro_id   = None
        try:
            with open("/etc/os-release", encoding="utf-8") as fp:
                for line in fp:
                    if line.startswith("NAME="): distro_name = line.split("=", 1)[-1].strip().strip('"')
                    if line.startswith("VERSION_ID="): distro_id = line.split("=", 1)[-1].strip().strip('"')
        except FileNotFoundError: pass

        if distro_name and distro_id: product = f'{distro_name} {distro_id}'
        else: product = 'Linux'

        kernel = platform.release()
        if '-' in kernel: kernel = kernel.split('-', 1)[0]
        if kernel.count('.') > 2: kernel = '.'.join(kernel.split('.')[:3])
        return product, kernel

    if os_name == "windows":
        name, version = _windows_info()
        return f"{name} (b-{version}, {arch})"

    elif os_name == "macos":
        name, version = _mac_info()
        rosetta_info = ', Rosetta' if is_rosetta else ''
        return f"{name} (b-{version}, {arch}{rosetta_info})"

    elif os_name == "linux":
        distro, kernel = _linux_info()
        docker_info = ', Docker' if is_docker else ''
        return f"{distro} (k-{kernel}, {arch}{docker_info})"

    else: return f'Unknown OS ({arch})'


# Formats and returns the detailed BuddyServers version as a string
def format_version() -> str:

    # Format build type
    if not is_official: build_type = 'unofficial-dev'
    elif dev_version:   build_type = 'beta'
    else:               build_type = build_data['type']

    formatted = f'v{app_version}-{build_type}'

    # Append build number if it's an official development build
    if build_data["version"] and dev_version:
        formatted += f'.{build_data["version"]}'

    # Append operating system information
    formatted += f' - {format_os()}'
    return formatted


# Formats and returns CPU data as a string
def format_cpu() -> str:
    cpu_arch = platform.architecture()
    if len(cpu_arch) > 1: cpu_arch = cpu_arch[0]
    try:    freq = round((psutil.cpu_freq().max) / 1000, 2)
    except: freq = 0.0
    return f"{psutil.cpu_count(False)} ({psutil.cpu_count()}) C/T @ {freq} GHz ({cpu_arch.replace('bit', '-bit')})"


# Formats and returns RAM data as a string
def format_ram() -> str:
    return f"{round(psutil.virtual_memory().used / 1073741824, 2)} / {round(psutil.virtual_memory().total / 1073741824)} GB"


# </editor-fold>



# -------------------------------------------- Network Operations ------------------------------------------------------
# <editor-fold desc="Network Operations">

# Cache for displaying the user's public IP address
def get_public_ip() -> str:
    global public_ip
    if app_config.enable_ip_lookup:
        public_ip = requests.get('https://api.ipify.org', timeout=5).content.decode('utf-8')
    return public_ip
public_ip: str = ""

# Global Cloudscraper object for global app use
def return_scraper(url_path: str, head=False, params=None) -> requests.Response:
    global global_scraper

    if not global_scraper:
        global_scraper = cloudscraper.create_scraper(
            browser = {'custom': f'{app_title}/{app_version}', 'platform': os_name, 'mobile': False},
        )

    return global_scraper.head(url_path) if head else global_scraper.get(url_path, params=params)
global_scraper: cloudscraper.CloudScraper = None


# Return HTML content or status code (using Cloudscraper)
def get_url(url: str, return_code=False, only_head=False, return_response=False, params=None) -> requests.Response:
    global global_scraper
    max_retries = 10
    for retry in range(0, max_retries + 1):
        try:
            html = return_scraper(url, head=(return_code or only_head), params=params)
            send_log('get_url', f"request to '{url}': {html.status_code}")
            return html.status_code if return_code \
                else html if (only_head or return_response) \
                else BeautifulSoup(html.content, 'html.parser')

        except cloudscraper.exceptions.CloudflareChallengeError as e:
            global_scraper = None
            if retry >= max_retries:
                send_log('get_url', f"exceeded max retries to '{url}': {format_traceback(e)}", 'error')
                raise ConnectionRefusedError("The cloudscraper connection has failed")
            else: time.sleep((retry / 3))

        except requests.exceptions.MissingSchema:
            pass

        except Exception as e:
            send_log('get_url', f"error requesting '{url}': {format_traceback(e)}", 'error')
            raise e


# Download a file with Cloudscraper and return data if the downloaded file exists
def cs_download_url(url: str, file_name: str, destination_path: str) -> bool:
    global global_scraper
    max_retries = 10
    send_log('cs_download_url', f"requesting from '{url}' to download '{file_name}' to '{destination_path}'...")
    for retry in range(0, max_retries + 1):
        try:
            web_file = return_scraper(url)
            full_path = os.path.join(destination_path, file_name)
            folder_check(destination_path)
            with open(full_path, 'wb') as file:
                file.write(web_file.content)

            send_log('cs_download_url', f"download of '{file_name}' complete: '{full_path}'")
            return os.path.exists(full_path)

        except cloudscraper.exceptions.CloudflareChallengeError as e:
            global_scraper = None
            if retry >= max_retries:
                send_log('cs_download_url', f"exceeded max retries to '{url}': {format_traceback(e)}", 'error')
                raise ConnectionRefusedError("The cloudscraper connection has failed")
            else: time.sleep((retry / 3))

        except Exception as e:
            send_log('cs_download_url', f"error requesting '{url}': {format_traceback(e)}", 'error')
            raise e


# Download file from URL to directory (not using Cloudscraper)
def download_url(url: str, file_name: str, output_path: str, progress_func=None) -> str or None:
    send_log('download_url', f"requesting from '{url}' to download '{file_name}' to '{output_path}'...")
    headers = {'User-Agent': 'Mozilla/5.0'}
    response = requests.get(url, headers=headers, stream=True)
    try: response.raise_for_status()
    except Exception as e:
        send_log('download_url', f"request to '{url}' error: {format_traceback(e)}", 'error')
        raise e

    file_path = os.path.join(output_path, file_name)
    folder_check(output_path)

    with open(file_path, 'wb') as file:
        total_length = response.headers.get('content-length')
        if total_length is None:  # no content length header
            file.write(response.content)
            if progress_func:
                progress_func(1, 1, 1)
        else:
            total_length = int(total_length)
            chunk_size = 8192
            for chunk, data in enumerate(response.iter_content(chunk_size=chunk_size), 0):
                file.write(data)
                if progress_func:
                    progress_func(chunk, chunk_size, total_length)

    if os.path.isfile(file_path):
        send_log('download_url', f"download of '{file_name}' complete: '{file_path}'")
        return file_path


# Returns the private IP address of the primary NIC
def get_private_ip() -> str:
    global is_docker

    # Try to get the host IP first if running in Docker
    if is_docker:
        try:
            host = socket.gethostbyname("host.docker.internal")
            if host and not host.startswith("127."): return host
        except Exception: pass

    # Otherwise, get the default static route
    with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as s:
        s.settimeout(0)
        try:
            # doesn't even have to be reachable
            s.connect(('10.254.254.254', 1))
            return s.getsockname()[0]
        except Exception: pass

    return '127.0.0.1'


# Check if port is open on host
def check_port(ip: str, port: int, timeout=120) -> bool:

    # Check connectivity
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    sock.settimeout(timeout)
    result = sock.connect_ex((ip, port))

    # Log connectivity
    success = result == 0
    if success: send_log('check_port', f"successfully connected to '{ip}:{port}'")
    elif debug: send_log('check_port', f"could not connect to '{ip}:{port}': timed out", 'error')

    return success


# Verify a properly formatted IPv4 address
def check_ip(addr: str, restrict=True) -> bool:

    if isinstance(addr, dict):
        return False

    validIP = False

    if addr.count(".") == 3:

        octets = addr.split(".")
        if len(octets) == 4:

            try:
                x = 1
                for octet in octets:
                    float(octet)
                    octet = int(octet)

                    if octet in range(0, 255) or (x < 4 and octet == 255):
                        validIP = True

                        if (x == 4 and octet == 0) and restrict is True:
                            validIP = False
                            break

                    else:
                        validIP = False
                        break

                    x += 1

            except ValueError:
                validIP = False

    return validIP


# Verify a properly formatted subnet prefix
def check_subnet(addr: str) -> bool:
    if addr.count(".") == 3 and "/" in addr:
        return (int(addr.split("/")[1]) in range(16, 31)) and check_ip(addr.split("/")[0], False)

    elif addr.count(".") == 3 and "!w" in addr:
        return check_ip(addr.replace("!w", "").strip(), False)

    else:
        return False


# </editor-fold>



# ----------------------------------------- App / Lifecycle Functions --------------------------------------------------
# <editor-fold desc="Lifecycle Functions">


# Variables for use in the desktop UI
background_color:         tuple = (0.115, 0.115, 0.182, 1)

fonts = {
    'regular':      'Figtree-Regular',             'medium':       'Figtree-Medium',
    'bold':         'Figtree-Bold',                'very-bold':    'Figtree-ExtraBold',
    'italic':       'ProductSans-BoldItalic',      'mono-regular': 'Inconsolata-Regular',
    'mono-medium':  'Mono-Medium',                 'mono-bold':    'Mono-Bold',
    'mono-italic':  'SometypeMono-RegularItalic',  'icons':        'SosaRegular.ttf'
}

# Bigboi server manager
server_manager:  'core.server.manager.ServerManager' = None

# Global script object for IDE suggestions
script_obj:      'core.server.amscript.ScriptObject' = None

# Global instance of the Discord presence manager from the desktop UI
discord_presence: 'ui.desktop.utility.DiscordPresenceManager' = None

# Flag to prevent the app from being closed during sensitive operations
ignore_close:          bool = False

# Splash message displayed in logs and title screen
session_splash:         str = ""

# For menu tracking with logging
footer_path:            str = ""
last_widget:       'Widget' = None

# Lock for input validation while the app is searching for a version
version_loading:       bool = False

# Load build data from attached file (if it exists)
# {"type":"development","version":"1384","branch":"ci-changes","commit":"dd139adb1f2890e23509c489ef39e99651f968bb","repo":"ShuvoSync/BuddyServers"}
build_data:  dict[str, Any] = {"type": "dev", "version": None, "branch": None, "commit": None, "repo": "ShuvoSync/BuddyServers"}

# If app is compiled in the main repo (set in 'build_data')
is_official:           bool = False

# If app is compiled as a development build (set in 'build_data')
dev_version:           bool = False

# If the app is online (set in 'check_app_updates()')
app_online:            bool = False

# If the app is the same version as the latest release (set in 'check_app_updates()')
app_latest:            bool = True

# Flag to change exit behavior if the app is restarting
restart_flag:          bool = False

# List of PIDs for all launched multi-processes
sub_processes:    list[int] = []

# Only True if running in a multiprocess context, in case this module gets imported again
is_child_process:   bool = multiprocessing.current_process().name != "MainProcess"

# Configure SSL directories and load internal CA lists
if os_name == 'linux' and app_compiled:
    os.environ['SSL_CERT_DIR']  = paths.executable_folder
    os.environ['SSL_CERT_FILE'] = os.path.join(paths.executable_folder, 'ca-bundle.crt')

elif os_name == 'macos' and app_compiled:
    os.environ['SSL_CERT_DIR']  = os.path.join(paths.executable_folder, 'certifi')
    os.environ['SSL_CERT_FILE'] = os.path.join(paths.executable_folder, 'certifi', 'cacert.pem')

# Global data for scraping the latest release from GitHub
update_data: dict[str, Any] = {
    "version":    '',
    "type":       None,
    "urls":       {'windows': None, 'linux': None, 'linux-arm64': None, 'macos': None},
    "md5":        {'windows': None, 'linux': None, 'linux-arm64': None, 'macos': None},
    "desc":       '',
    "web_url":    None,
    "reboot-msg": [],
    "auto-show":  True
}


# Grabs amscript files from the GitHub repo for downloading internally
def get_repo_scripts() -> list:
    from source.core.server import amscript
    global ams_web_list

    try:
        latest_commit = requests.get("https://api.github.com/repos/ShuvoSync/BuddyServers/commits").json()[0]['sha']
        repo_data = requests.get(
            f"https://api.github.com/repos/ShuvoSync/BuddyServers/git/trees/{latest_commit}?recursive=1").json()

        script_dict = {}
        ams_list = []
        root_url = "https://raw.githubusercontent.com/ShuvoSync/BuddyServers/main/"

        # Organize all script files
        for file in repo_data['tree']:
            if file['path'].startswith('amscript-library'):
                if "/" in file['path']:
                    root_name = file['path'].split("/")[1]
                    if root_name not in script_dict:
                        script_dict[root_name] = {
                            'url': f'https://github.com/ShuvoSync/BuddyServers/tree/main/{quote(file["path"])}'}
                    if root_name + "/" in file['path']:
                        script_dict[root_name][os.path.basename(file['path'])] = f"{root_url}{quote(file['path'])}"

        # Concurrently add scripts to ams_list
        def add_to_list(script, *args):
            ams_list.append(amscript.AmsWebObject(script))

        with ThreadPoolExecutor(max_workers=10) as pool:
            pool.map(add_to_list, script_dict.items())

        # Sort list by title
        ams_list = sorted(ams_list, key=lambda x: x.title, reverse=True)

    except:
        ams_list = []

    ams_web_list = ams_list
    return ams_list
ams_web_list: list['core.server.amscript.AmsWebObject'] = []

# Clean-up amscript IDE cache
def clear_script_cache(script_path):
    json_path = None

    # Ignore if the script isn't in the app directory
    if not script_path.startswith(paths.app_folder):
        return

    # Attempt to delete the file
    try:
        file_name = os.path.basename(script_path).split('.')[0] + '.json'
        if script_path.startswith(paths.telepath_script_temp):
            json_dir = os.path.join(paths.cache, 'ide', 'fold-regions', 'telepath')
        else:
            json_dir = os.path.join(paths.cache, 'ide', 'fold-regions', 'local')
        json_path = os.path.join(json_dir, file_name)
        if os.path.isfile(json_path):
            os.remove(json_path)

    # Log on failure
    except Exception as e:
        send_log('clear_script_cache', f"failed to remove IDE script cache '{json_path}': {format_traceback(e)}", 'error')


# Returns 'True' if latest is greater than current
def check_app_version(current: str, latest: str, limit=None) -> bool:

    # Makes list the size of the greatest list
    def normalize(l, s):
        if len(l) < s:
            for x in range(s - len(l)):
                l.append(0)
        return l

    c_list = [int(x) for x in current.split(".")]
    l_list = [int(x) for x in latest.split(".")]
    max_size = max(len(c_list), len(l_list))
    normalize(c_list, max_size)
    normalize(l_list, max_size)

    for x in range(max_size):

        if limit:
            if x >= limit:
                return False

        if l_list[x] > c_list[x]:
            return True

        elif c_list[x] > l_list[x]:
            return False
    else:
        return False


# Check if client has an internet connection
def check_app_updates() -> bool:
    global project_repo, app_version, app_latest, app_online, update_data

    # Check if updates are available
    try:

        # Make a request to the GitHub API to see if app is online (they have a CDN, it's faster)
        latest_release = f"https://api.github.com/repos{project_repo.split('.com')[1]}/releases/latest"
        response       = requests.get(latest_release, timeout=5)
        status_code    = response.status_code
        app_online     = status_code in (200, 403)
        release_data   = response.json()

        # Don't automatically prompt or check for updates if specified off in the config
        if not app_config.auto_update or not is_official:
            app_latest = True
            return False


        # -------------------------------- First, check the stable release channel -------------------------------------
        try:

            # Get MD5 checksum data from release description
            description, md5_str   = release_data['body'].split("MD5 Checksums", 1)
            update_data['desc']    = description.replace("- ", "â€¢ ").strip().replace('<br>', '\n').replace("`", "")
            update_data['type']    = "release"
            update_data['web_url'] = f'{project_repo}/releases/latest'

            checksum = ""
            for line in md5_str.splitlines():
                if line == '`': continue

                if checksum:
                    update_data['md5'][checksum] = line.strip()
                    checksum = ""; continue

                elif "windows" in line.lower():
                    checksum = "windows"; continue

                elif "macos" in line.lower():
                    checksum = "macos"; continue

                elif "linux arm64" in line.lower():
                    checksum = "linux-arm64"; continue

                elif "linux" in line.lower():
                    checksum = "linux"; continue

        except: pass


        # Format release data
        version = release_data['name']
        if "-" in version:    update_data['version'] = version[1:].split("-")[0].strip()
        elif " " in version:  update_data['version'] = version[1:].split(" ")[0].strip()
        elif "v" in version:  update_data['version'] = version[1:].strip()
        else:                 update_data['version'] = app_version


        # Retrieve the download links by mapping assets to their OS version
        for file in release_data['assets']:

            if 'windows' in file['name']:
                update_data['urls']['windows'] = file['browser_download_url']; continue

            elif 'macos' in file['name']:
                update_data['urls']['macos'] = file['browser_download_url']; continue

            elif 'linux-arm64' in file['name']:
                update_data['urls']['linux-arm64'] = file['browser_download_url']; continue

            elif 'linux' in file['name']:
                update_data['urls']['linux'] = file['browser_download_url']; continue


        # Check if app needs to be updated, and URL was successful
        if (check_app_version(str(app_version), str(update_data['version']))
        or (str(app_version) == str(update_data['version']) and dev_version)):
            app_latest = False
            return True




        # ---------------- If the app is in the development release channel, check if it needs an update ---------------

        elif dev_version:
            dev_update_data: dict[str, Any] = deepcopy(update_data)
            commit_metadata: dict[str, str] = {}
            artifacts_url:              str = f'{ci_artifacts}/public.php/dav/files/public/Artifacts/'
            namespaces:      dict[str, str] = {'d': 'DAV:'}

            # Parses item properties of a WebDav object
            def prop_find(url: str, depth='1') -> ElementTree:
                response = requests.request('PROPFIND', url, headers={'Depth': depth}, timeout=20)
                response.raise_for_status()
                return ElementTree.fromstring(response.text).findall('d:response', namespaces)

            # Returns '(name, href, last_modified)' for each subfolder
            def list_folders(url: str) -> list[tuple[str, str, Optional[dt]]]:
                folder_list = []
                for r in prop_find(url):
                    href = unquote(r.findtext('d:href', namespaces=namespaces) or '')

                    # Skip the currently selected directory
                    if href.rstrip('/').endswith(artifacts_url.rstrip('/').rsplit('/', 1)[-1]): continue

                    prop = r.find('d:propstat/d:prop', namespaces)

                    # Ignore other folders, or skip if the folder doesn't have properties somehow
                    if prop is None: continue
                    if prop.find('d:resourcetype/d:collection', namespaces) is None: continue

                    lm = prop.findtext('d:getlastmodified', namespaces=namespaces)
                    folder_list.append((
                        href.rstrip('/').split('/')[-1],
                        artifacts_url + quote(href.rstrip('/').split('/')[-1]) + '/',
                        parsedate_to_datetime(lm) if lm else None
                    ))
                return folder_list

            # Returns (name, size, last_modified, url) for each file in a folder
            def list_files(url: str) -> list[tuple[str, int, Optional[dt], str]]:
                file_list = []

                for r in prop_find(url):
                    href = unquote(r.findtext('d:href', namespaces=namespaces) or '')

                    # Skip the root folder
                    if href.rstrip('/') == url.rstrip('/').replace(artifacts_url.rstrip('/'), '').rstrip('/'): continue

                    prop = r.find('d:propstat/d:prop', namespaces)

                    # Ignore other folders, or skip if the file doesn't have properties somehow
                    if prop is None: continue
                    if prop.find('d:resourcetype/d:collection', namespaces) is not None: continue

                    name = href.rstrip('/').split('/')[-1]
                    size = int(prop.findtext('d:getcontentlength', default='0', namespaces=namespaces) or 0)
                    lm = parsedate_to_datetime(prop.findtext('d:getlastmodified', namespaces=namespaces) or "")

                    file_list.append((name, size, lm, url + quote(name)))

                return file_list


            # Select the last modified folder
            folders = list_folders(artifacts_url)
            folders.sort(key=lambda x: x[2] or 0, reverse=True)
            _, target, _ = folders[0]

            # Retrieve the download links by mapping artifacts to their OS version
            for name, size, last_modified, url in list_files(target):

                # Retrieve & parse metadata file separately
                if name.startswith('commit-metadata'):
                    data, checksum = requests.get(url).text.split("Checksums (MD5):")
                    dev_update_data['desc'] = re.sub(r':\s+', ':     ', data.strip())

                    # Parse metadata at the top
                    for line in data.splitlines():
                        if line.strip():
                            k, v = line.split(':', 1); commit_metadata[k.strip().lower()] = v.strip()

                    # Retrieve MD5 hashes for all files
                    for line in checksum.splitlines():
                        if line.strip() and 'alpine' not in line:
                            k, v = line.split(':', 1); dev_update_data['md5'][k.strip().lower()] = v.strip().lower()

                elif 'windows' in name:
                    dev_update_data['urls']['windows'] = url; continue

                elif 'macos' in name:
                    dev_update_data['urls']['macos'] = url; continue

                elif 'linux-arm64' in name:
                    dev_update_data['urls']['linux-arm64'] = url; continue

                elif 'linux' in name:
                    dev_update_data['urls']['linux'] = url; continue


            # Process commit data
            dev_update_data['type'] = "release" if commit_metadata['branch'] == "main" else "development"
            update_version      = target.split(artifacts_url)[-1].split('-')[0]
            update_build        = commit_metadata['build']

            # Format build type
            if 'dev' in dev_update_data['type']: build_type = 'beta'
            else: build_type = dev_update_data['type']

            formatted = f'{update_version}-{build_type}'

            # Append build number if it's an official development build
            if update_build and 'dev' in dev_update_data['type']:
                formatted += f'.{update_build}'

            dev_update_data['version'] = formatted
            dev_update_data['web_url'] = commit_metadata['url']



            # Once dev build is scraped, check data versions to compare if update is needed
            # Check if app needs to be updated, and URL was successful
            if int(build_data['version']) < int(update_build):
                update_data = dev_update_data
                app_latest  = False
                return True


    except Exception as e:
        send_log('check_app_updates', f"error checking for updates: {format_traceback(e)}", 'error')

    return False


# Downloads the latest version of BuddyServers if available
def download_update(progress_func=None):

    def hook(a, b, c):
        if progress_func:
            progress_func(round(100 * a * b / c))


    # Select URL & MD5 key for this platform
    if os_name == 'linux' and is_arm:
        update_url = update_data['urls']['linux-arm64']
        md5_key    = 'linux-arm64'
    else:
        update_url = update_data['urls'][os_name]
        md5_key = os_name

    if not update_url: return False


    # Determine the type of file that's going to be downloaded
    try:    url_path = unquote(urlparse(update_url).path)
    except: url_path = update_url
    ext = os.path.splitext(url_path)[1].lower()

    if ext == ".zip":
        download_name = "BuddyServers.zip"
        binary_name   = {'macos': 'BuddyServers.app', 'windows': 'BuddyServers.exe'}.get(os_name, 'BuddyServers')

    # The file itself is the artifact
    elif ext == ".dmg":
        download_name = "BuddyServers.dmg"
        binary_name = None

    # The file itself is the artifact
    else:
        download_name = "BuddyServers.exe" if os_name == "windows" else "BuddyServers"
        binary_name = None


    # Attempt to download up to 3 times
    attempts    = 3
    fail_count  = 0
    new_version = update_data["version"]
    last_error  = None

    send_log("download_update", f"downloading {app_title} v{new_version} from: {update_url}", "info")

    while fail_count < attempts:
        safe_delete(paths.downloads)
        folder_check(paths.downloads)

        try:
            if progress_func and fail_count > 0:
                progress_func(0)

            # Download
            download_url(update_url, download_name, paths.downloads, hook)
            downloaded_path = os.path.join(paths.downloads, download_name)

            # Extract download if it's an archive
            if ext == ".zip":
                extract_archive(downloaded_path, paths.downloads)
                os.remove(downloaded_path)
                binary_file = os.path.join(paths.downloads, binary_name)

            elif ext == ".dmg":
                binary_file = downloaded_path

            else:
                binary_file = downloaded_path
                if os_name != "windows":
                    try: os.chmod(binary_file, 0o755)
                    except: pass

            # Verify hash
            if os.path.isfile(binary_file) and get_checksum(binary_file) == update_data["md5"][md5_key]:

                if progress_func:
                    progress_func(100)

                send_log("download_update", f"successfully downloaded {app_title} v{new_version} to: '{binary_file}'", "info")
                return True

            # File missing or checksum mismatch
            fail_count += 1

        except Exception as e:
            last_error = format_traceback(e)
            fail_count += 1


    if last_error: send_log("download_update", f"failed to download {app_title} v{new_version}: {last_error}", "error")
    return False


# Restarts BuddyServers by dynamically generating a script
def restart_app(*a, with_flags: list[str] = None):
    global restart_flag

    if not app_compiled:
        return send_log('restart_app', "can't restart in script mode", 'warning')

    # Setup environment
    retry_wait = 30
    tty = get_parent_tty()
    executable = os.path.basename(paths.launch_path)
    script_name = 'buddyservers-reboot'
    script_path = None
    restart_flag = True

    # Add flags when launching
    flags = f"{' --debug' if debug else ''}{' --headless' if headless else ''}"
    if with_flags: flags += f" {' '.join(flag for flag in set(with_flags) if flag not in flags)}"

    folder_check(paths.temp)
    send_log('restart_app', f'attempting to restart {app_title}...', 'warning')



    # Generate Windows script to restart
    if os_name == "windows":
        script_name = f'{script_name}.bat'
        script_path = os.path.join(paths.temp, script_name)

        with open(script_path, 'w+') as script:
            script_content = (

f""":: Kill the process
taskkill /f /im \"{executable}\"

:: Wait for it to exit (max {retry_wait}s)
set /a count=0
:waitloop
tasklist /fi "imagename eq {executable}" | find /i \"{executable}\" >nul
if %errorlevel%==0 (
    timeout /t 1 /nobreak >nul
    set /a count+=1
    if %count% LSS {retry_wait} goto waitloop
)

:: Launch the original executable
start \"\" \"{paths.launch_path}\"{flags}
del \"{script_path}\"""")

            script.write(script_content)
            send_log('restart_app', f"writing to '{script_path}':\n{script_content}")

        run_proc(f"\"{script_path}\" > nul 2>&1")
        sys.exit(0)



    # Generate Linux/macOS script to restart
    else:
        script_name = f'{script_name}.sh'
        script_path = os.path.join(paths.temp, script_name)
        escaped_launch_path = shlex.quote(paths.launch_path)

        with open(script_path, 'w+') as script:
            script_content = (

f"""#!/bin/bash
PID={os.getpid()}

# Kill the process
kill "$PID"

# Wait for it to exit (max {retry_wait}s)
for i in {{1..{retry_wait}}}; do
    if ! kill -0 "$PID" 2>/dev/null; then
        break
    fi
    sleep 1
done

# Force kill if it's still not closed
if kill -0 "$PID" 2>/dev/null; then
    kill -9 "$PID" 2>/dev/null
fi

# Launch the original executable
TTY={tty}
if [ -n "$TTY" ] && [ -e "$TTY" ] && [ -w "$TTY" ]; then
    # Reuse the original terminal for STDIO
    exec {escaped_launch_path}{flags} <"$TTY" >"$TTY" 2>&1 &
else
    # Original terminal wasn't found, background quietly
    exec {escaped_launch_path}{flags} >/dev/null 2>&1 &
fi
rm \"{script_path}\"""")

            script.write(script_content)
            send_log('restart_app', f"writing to '{script_path}':\n{script_content}")

    run_detached(script_path)
    sys.exit(0)


# Restarts BuddyServers, creates a symlink to 'new_path', & moves the app folder to 'new_path' before restarting
def restart_move_app(*a, new_path: str, with_flags: list[str] = None):
    global restart_flag

    if not app_compiled:
        return send_log('restart_move_app', "can't restart in script mode", 'warning')

    # Try to ensure WRX permissions (and traverse on POSIX) at target_dir
    def _check_rwx_dir(target_dir: str) -> tuple[bool, str]:
        try:
            os.makedirs(target_dir, exist_ok=True)
        except Exception as e:
            return False, f"cannot create directory: {e}"

        # POSIX execute bit is "traverse" for dirs
        if os_name != 'windows':
            if not os.access(target_dir, os.W_OK | os.X_OK):
                return False, f"'{username}' is missing write & execute permissions"

        # Write test
        try:
            test_path = os.path.join(target_dir, f'.perm_test_{os.getpid()}')
            with open(test_path, 'wb') as f:
                f.write(b'ok')
            os.remove(test_path)
        except Exception as e:
            return False, f"write test failed: {e}"

        return True, ""

    # Ensure the parent directory of path is writable
    def _parent_writable(path: str) -> tuple[bool, str]:
        parent = os.path.dirname(path)
        try:
            os.makedirs(parent, exist_ok=True)
        except Exception as e:
            return False, f"cannot create parent dir '{parent}': {e}"

        try:
            probe = os.path.join(parent, f'.perm_probe_{os.getpid()}')
            with open(probe, 'wb') as f:
                f.write(b'ok')
            os.remove(probe)
        except Exception as e:
            return False, f"parent write test failed for '{parent}': {e}"

        if os_name != 'windows' and not os.access(parent, os.W_OK | os.X_OK):
            return False, f"missing write/execute on parent '{parent}'"
        return True, ""

    # Verify the destination filesystem has at least size(src_dir) + padding GiB free
    def _check_dest_space(src_dir: str, dest_parent: str, padding_gib: int = 15) -> tuple[bool, str]:

        def _fmt(n: int) -> str:
            units = ("B", "KB", "MB", "GB", "TB")
            i = 0
            x = float(n)
            while x >= 1000 and i < len(units) - 1:
                x /= 1000.0
                i += 1
            return f"{x:.1f} {units[i]}"

        # Compute directory size without following symlinks
        def _dir_size_bytes(root: str) -> int:
            if not os.path.exists(root):
                return 0
            total = 0
            stack = [root]
            while stack:
                d = stack.pop()
                try:
                    with os.scandir(d) as it:
                        for e in it:
                            try:
                                if e.is_symlink():
                                    continue
                                if e.is_file(follow_symlinks=False):
                                    total += e.stat(follow_symlinks=False).st_size
                                elif e.is_dir(follow_symlinks=False):
                                    stack.append(e.path)
                            except Exception:
                                continue
                except Exception:
                    continue
            return total

        try:
            src_bytes = _dir_size_bytes(src_dir)
        except Exception as e:
            return False, f"failed to measure source size: {e}"

        # Ensure we can resolve the FS that will hold dest_parent
        path_for_fs = dest_parent
        try: os.makedirs(path_for_fs, exist_ok=True)
        except Exception: path_for_fs = os.path.dirname(path_for_fs.rstrip(os.sep)) or os.sep

        try: free_bytes = disk_usage(path_for_fs).free
        except Exception as e: return False, f"failed to query free space at destination: {e}"

        required = src_bytes + int(padding_gib * (1024 ** 3))
        if free_bytes < required:
            return False, (
                f"insufficient free space: need â‰¥ {_fmt(required)} "
                f"have {_fmt(free_bytes)}"
            )

        return True, (
            f"OK: data {_fmt(src_bytes)} + padding {padding_gib} GiB â‰¤ free {_fmt(free_bytes)}"
        )

    # To check if path is a descendant of root
    def _in_tree(p: str, root: str) -> bool:
        def _canon(p: str) -> str: return os.path.normcase(os.path.abspath(p.rstrip("\\/")))
        try: return os.path.commonpath([_canon(p), _canon(root)]) == _canon(root)
        except ValueError: return False  # different drives / UNC vs local


    # Normalize inputs/paths
    new_path     = os.path.abspath(new_path)
    app_basename = os.path.basename(paths.app_folder)
    dest_parent  = new_path
    dest_dir     = os.path.join(dest_parent, app_title)
    link_path    = paths.app_folder
    link_parent  = os.path.dirname(link_path)
    real_current = os.path.realpath(link_path) if os.path.exists(link_path) else link_path

    # Revert mode to move data back to the default location if new_path is descendant of appdata (no symlink/junction)
    reset_mode = _in_tree(new_path, paths.appdata)
    if reset_mode:
        dest_parent = link_parent
        dest_dir    = link_path
    else:
        dest_parent = new_path
        dest_dir    = os.path.join(dest_parent, app_title)


    # Prevent action if source path matches the destination
    if os.path.normcase(os.path.normpath(real_current)) == os.path.normcase(os.path.normpath(dest_dir)):
        send_log('restart_move_app', "app data already at destination; nothing has been done", 'warning')
        return False

    # Ensure dest_dir doesn't already exist
    if os.path.exists(dest_dir) and os.path.normcase(os.path.realpath(dest_dir)) != os.path.normcase(os.path.realpath(real_current)):
        send_log('restart_move_app', f"destination already exists: '{dest_dir}'", 'error')
        return False

    # Ensure that the user, and by extension BuddyServers, has permission to write to the destination
    ok, why = _check_rwx_dir(dest_parent)
    if not ok:
        send_log('restart_move_app', f"destination not writable: {why}", 'error')
        return False

    # Ensure the destination parent is writeable
    ok, why = _parent_writable(link_path)
    if not ok:
        send_log('restart_move_app', f"link parent not writable: {why}", 'error')
        return False

    # Ensure the destination partition has enough free space
    ok, why = _check_dest_space(real_current, dest_parent)
    if not ok:
        send_log('restart_move_app', f"destination free-space check failed: {why}", 'error')
        return False

    # Rename a temporary probe inside the source folder to check if the source is in use
    try:
        if os.path.isdir(real_current):
            probe_a = os.path.join(real_current, f'.move_probe_{os.getpid()}_a')
            probe_b = os.path.join(real_current, f'.move_probe_{os.getpid()}_b')
            with open(probe_a, 'wb') as f: f.write(b'probe')
            os.replace(probe_a, probe_b)
            os.remove(probe_b)
    except Exception as e:
        send_log('restart_move_app', f"pre-move probe failed (source in use): {e}", 'error')
        return False


    # Setup environment
    retry_wait = 30
    tty = get_parent_tty()
    executable = os.path.basename(paths.launch_path)
    script_name = 'buddyservers-reboot-move'
    script_path = None
    restart_flag = True

    # Add flags when launching
    flags = f"{' --debug' if debug else ''}{' --headless' if headless else ''}"
    if with_flags: flags += f" {' '.join(flag for flag in set(with_flags) if flag not in flags)}"

    folder_check(paths.temp)
    log_content = f"attempting to relocate 'app_folder' then restart {app_title}:\nlink_path: {link_path}\nreal_current: {real_current}\ndest_dir:{dest_dir}"
    send_log('restart_move_app', log_content, 'warning')

    # Generate Windows script to move & restart (using a junction for a symlink)
    if os_name == "windows":
        script_name = f'{script_name}.bat'
        script_path = os.path.join(paths.os_temp, script_name)

        # Escape double-quotes for embedding
        lp     = link_path.replace('"', r'\"')
        rc     = real_current.replace('"', r'\"')
        dp     = dest_parent.replace('"', r'\"')
        dd     = dest_dir.replace('"', r'\"')

        with open(script_path, 'w+', encoding='utf-8') as script:
            script_content = (

f"""setlocal EnableExtensions EnableDelayedExpansion
:: Kill the process
taskkill /f /im \"{executable}\"
taskkill /f /im playit.exe
taskkill /f /im java.exe

:: Wait for it to exit (max {retry_wait}s)
set /a count=0
:waitloop
tasklist /fi "imagename eq {executable}" | find /i \"{executable}\" >nul
if !errorlevel! == 0 (
    timeout /t 1 /nobreak >nul
    set /a count+=1
    if !count! LSS {retry_wait} goto waitloop
)

:: Variables
set "LINK_PATH={lp}"
set "REAL_SRC={rc}"
set "DEST_PARENT={dp}"
set "DEST_DIR={dd}"
set "RESET_MODE={1 if reset_mode else 0}"

:: Ensure destination parent exists
if not exist "%DEST_PARENT%" mkdir "%DEST_PARENT%"

:: If the expected path is a link (junction/symlink), remove the link (don't touch real dirs)
fsutil reparsepoint query "%LINK_PATH%" >nul 2>&1
if !errorlevel! EQU 0 rmdir "%LINK_PATH%"

:: Ensure destination exists
if not exist "%DEST_DIR%" mkdir "%DEST_DIR%"

:: Move data from original path
if /I not "%REAL_SRC%"=="%DEST_DIR%" if exist "%REAL_SRC%" (
    robocopy "%REAL_SRC%" "%DEST_DIR%" /E /MOVE /R:2 /W:5 /XJ
    set "RC=!ERRORLEVEL!"
    if !RC! GEQ 8 (
        echo Robocopy failed with code !RC!
        exit /b !RC!
    )
    :: Remove now-empty source folder so mklink can succeed
    rmdir "%REAL_SRC%" 2>nul
)

:: Create link: use /D for UNC/network targets, /J otherwise
if "%RESET_MODE%"=="0" (

    if exist "%LINK_PATH%" (
        echo Source path still exists; cannot create link at "%LINK_PATH%".
        exit /b 1
    )

    echo %DEST_DIR% | findstr /b "\\\\" >nul
    if !errorlevel! EQU 0 (
        mklink /D "%LINK_PATH%" "%DEST_DIR%"
    ) else (
        mklink /J "%LINK_PATH%" "%DEST_DIR%"
    )
)

:: Launch the original executable
start \"\" \"{paths.launch_path}\"{flags}
del \"{script_path}\"""")

            script.write(script_content)
            send_log('restart_move_app', f"writing to '{script_path}':\n{script_content}")

        run_proc(f"\"{script_path}\" > nul 2>&1")
        sys.exit(0)


    # Generate Linux/macOS script to move and restart (using a normal symlink)
    else:
        script_name = f'{script_name}.sh'
        script_path = os.path.join(paths.os_temp, script_name)
        escaped_launch_path = shlex.quote(paths.launch_path)

        # Quote for shell
        lp   = shlex.quote(link_path)
        rc   = shlex.quote(real_current)
        dp   = shlex.quote(dest_parent)
        dd   = shlex.quote(dest_dir)

        with open(script_path, 'w+', encoding='utf-8') as script:
            script_content = (

f"""#!/bin/bash
set -euo pipefail
PID={os.getpid()}

# Kill the process
kill "$PID" 2>/dev/null || true

# Wait for it to exit (max {retry_wait}s)
for i in {{1..{retry_wait}}}; do
    if ! kill -0 "$PID" 2>/dev/null; then
        break
    fi
    sleep 1
done

# Force kill if it's still not closed
if kill -0 "$PID" 2>/dev/null; then
    kill -9 "$PID" 2>/dev/null || true
fi

LINK_PATH={lp}
REAL_SRC={rc}
DEST_PARENT={dp}
DEST_DIR={dd}
RESET_MODE={1 if reset_mode else 0}

# Kill any processes running in the app directory
pkill -9 -f "$REAL_SRC" || true

# Ensure destination parent exists
mkdir -p "$DEST_PARENT"

# If LINK_PATH is a symlink, remove it (don't delete real dirs here)
if [ -L "$LINK_PATH" ]; then
    unlink "$LINK_PATH"
fi

# Move data if needed
if [ "$REAL_SRC" != "$DEST_DIR" ] && [ -e "$REAL_SRC" ]; then
    mv "$REAL_SRC" "$DEST_DIR"
fi

# Create symlink at expected location -> DEST_DIR
if [[ "$RESET_MODE" = "0" && ! -e "$LINK_PATH" ]]; then
    ln -s "$DEST_DIR" "$LINK_PATH"
fi

# Launch the original executable
TTY={tty}
if [ -n "$TTY" ] && [ -e "$TTY" ] && [ -w "$TTY" ]; then
    # Reuse the original terminal for STDIO
    exec {escaped_launch_path}{flags} <"$TTY" >"$TTY" 2>&1 &
else
    # Original terminal wasn't found, background quietly
    exec {escaped_launch_path}{flags} >/dev/null 2>&1 &
fi
rm \"{script_path}\" || true""")

            script.write(script_content)
            send_log('restart_move_app', f"writing to '{script_path}':\n{script_content}")

        run_detached(script_path)
        sys.exit(0)


# Restarts and updates BuddyServers by dynamically generating a script
def restart_update_app(*a, with_flags: list[str] = None):
    global restart_flag

    if not app_compiled:
        return send_log('restart_update_app', "can't restart in script mode", 'warning')

    # Setup environment
    retry_wait = 30
    tty = get_parent_tty()
    executable = os.path.basename(paths.launch_path)
    script_name = 'buddyservers-update'
    script_path = None
    restart_flag = True

    # Add flags when launching
    flags = f"{' --debug' if debug else ''}{' --headless' if headless else ''}"
    if with_flags: flags += f" {' '.join(flag for flag in set(with_flags) if flag not in flags)}"

    folder_check(paths.temp)

    new_version  = update_data['version']
    success_str  = f"BuddyServers was updated to v${new_version}$ successfully!"
    success_unix = fr"BuddyServers was updated to v\${new_version}\$ successfully!"
    failure_str  = "Something went wrong with the update"
    script_name  = 'buddyservers-update'
    update_log   = os.path.join(paths.temp, 'update-log')
    send_log('restart_update_app', f'attempting to restart {app_title} and update to v{new_version}...', 'warning')


    # Delete guide cache for the next update
    guide_cache = os.path.join(paths.cache, 'guide-cache.json')
    if os.path.exists(guide_cache):
        try: os.remove(guide_cache)
        except: pass



    # Generate Windows script to restart
    if os_name == "windows":
        script_name = f'{script_name}.bat'
        script_path = os.path.join(paths.temp, script_name)
        new_executable = os.path.join(paths.downloads, 'BuddyServers.exe')

        with open(script_path, 'w+') as script:
            script_content = (

f""":: Kill the process
taskkill /f /im \"{executable}\"

:: Wait for it to exit (max {retry_wait}s)
set /a count=0
:waitloop
tasklist /fi "imagename eq {executable}" | find /i \"{executable}\" >nul
if %errorlevel%==0 (
    timeout /t 1 /nobreak >nul
    set /a count+=1
    if %count% LSS {retry_wait} goto waitloop
)

:: Copy new update file to original path
copy /b /v /y "{new_executable}" "{paths.launch_path}"
if exist "{paths.launch_path}" if %ERRORLEVEL% EQU 0 (
    echo banner-success@{success_str} > "{update_log}"
) else (
    echo banner-failure@{failure_str} > "{update_log}"
)

:: Launch the new executable
start \"\" \"{paths.launch_path}\"{flags}
del \"{script_path}\"""")

            script.write(script_content)
            send_log('restart_update_app', f"writing to '{script_path}':\n{script_content}")

        run_proc(f"\"{script_path}\" > nul 2>&1")
        sys.exit(0)



    # Generate macOS script to restart
    elif os_name == 'macos':
        script_name = f'{script_name}.sh'
        script_path = os.path.join(paths.temp, script_name)
        escaped_launch_path = shlex.quote(paths.launch_path)
        dmg_path = os.path.join(paths.downloads, 'BuddyServers.dmg')

        with open(script_path, 'w+') as script:
            script_content = (

f"""#!/bin/bash
PID={os.getpid()}

# Kill the process
kill "$PID"

# Wait for it to exit (max {retry_wait}s)
for i in {{1..{retry_wait}}}; do
    if ! kill -0 "$PID" 2>/dev/null; then
        break
    fi
    sleep 1
done

# Force kill if it's still not closed
if kill -0 "$PID" 2>/dev/null; then
    kill -9 "$PID" 2>/dev/null
fi

# Utilize rsync to update the old app contents in place
hdiutil mount "{dmg_path}"
rsync -a /Volumes/BuddyServers/BuddyServers.app/ "{os.path.join(os.path.dirname(paths.launch_path), '../..')}"
errorlevel=$?
if [ -f "{paths.launch_path}" ] && [ $errorlevel -eq 0 ]; then
    echo banner-success@{success_unix} > "{update_log}"
else
    echo banner-failure@{failure_str} > "{update_log}"
fi

# Remove the update disk
hdiutil unmount /Volumes/BuddyServers
rm -rf "{dmg_path}"

# Launch the new executable
chmod +x "{paths.launch_path}"
TTY={tty}
if [ -n "$TTY" ] && [ -e "$TTY" ] && [ -w "$TTY" ]; then
    # Reuse the original terminal for STDIO
    exec {escaped_launch_path}{flags} <"$TTY" >"$TTY" 2>&1 &
else
    # Original terminal wasn't found, background quietly
    exec {escaped_launch_path}{flags} >/dev/null 2>&1 &
fi
rm \"{script_path}\"""")

            script.write(script_content)
            send_log('restart_update_app', f"writing to '{script_path}':\n{script_content}")

        run_proc(f"chmod +x \"{script_path}\" && bash \"{script_path}\" > /dev/null 2>&1")
        sys.exit(0)



    # Generate Linux script to restart
    else:
        script_name = f'{script_name}.sh'
        script_path = os.path.join(paths.temp, script_name)
        escaped_launch_path = shlex.quote(paths.launch_path)
        new_executable = os.path.join(paths.downloads, 'BuddyServers')

        with open(script_path, 'w+') as script:
            script_content = (

f"""#!/bin/bash
PID={os.getpid()}

# Kill the process
kill "$PID"

# Wait for it to exit (max {retry_wait}s)
for i in {{1..{retry_wait}}}; do
    if ! kill -0 "$PID" 2>/dev/null; then
        break
    fi
    sleep 1
done

# Force kill if it's still not closed
if kill -0 "$PID" 2>/dev/null; then
    kill -9 "$PID" 2>/dev/null
fi

# Copy new update file to original path
/bin/cp -rf "{new_executable}" "{paths.launch_path}"
errorlevel=$?
if [ -f "{paths.launch_path}" ] && [ $errorlevel -eq 0 ]; then
    echo banner-success@{success_unix} > "{update_log}"
else
    echo banner-failure@{failure_str} > "{update_log}"
fi

# Launch the new executable
chmod +x "{paths.launch_path}"
TTY={tty}
if [ -n "$TTY" ] && [ -e "$TTY" ] && [ -w "$TTY" ]; then
    # Reuse the original terminal for STDIO
    exec {escaped_launch_path}{flags} <"$TTY" >"$TTY" 2>&1 &
else
    # Original terminal wasn't found, background quietly
    exec {escaped_launch_path}{flags} >/dev/null 2>&1 &
fi
rm \"{script_path}\"""")

            script.write(script_content)
            send_log('restart_update_app', f"writing to '{script_path}':\n{script_content}")

    run_detached(script_path)
    sys.exit(0)


# Set by the respective UI to prevent the app from being closed
def allow_close(allow: bool, banner=''):
    global ignore_close
    ignore_close = not allow

    # Log that window was locked/unlocked
    verb        = 'locked' if ignore_close else 'unlocked'
    banner_verb = f'with banner: {banner.replace("$","")}' if banner else 'with no banner'
    send_log('allow_close', f'{verb} GUI window {banner_verb}')

    if banner and telepath_banner and app_config.telepath_settings['show-banners']:
        telepath_banner(banner, allow)


# Random splash message
def generate_splash(crash=False):
    global session_splash, headless

    splashes = [
        "Nothing is impossible, unless you can't do it.", "Every 60 seconds in Africa, a minute goes by.",
        "Did you know: you were born on your birthday.", "Okay, I'm here. What are your other two wishes?",
        "Sometimes when you close your eyes, you may not be able to see.",
        "Common sense is the most limited of all natural resources.", "Ah, yes. That will be $69,420.00",
        "Some mints can be very dangerous.", "Paper grows on trees.",
        "You forgot? No problem. It's USERNAME PASSWORD123.", "This is just like my Yamaha Motorcycle!",
        "n o t  c o o l  m a n!", "Existing is prohibited from the premises.", "no", "Oh no, the monster died!",
        "Black holes are essentially God divided by 0", "If you try and don't succeed, you probably shouldn't skydive",
        "On the other hand, you have different fingers.", "A day without sunshine is like night.",
        "?What are you doing here strangerÂ¿", "Get outta my swamp!", "Whoever put the word fun in funeral?",
        "A new day is like a new day.", "Everywhere is within walking distance if you have the time.",
        "empty blank", "Money doesnâ€™t buy happiness, but it does buy everything else.",
        "Congratulations! It's a pizza!", "Silence is golden, but duck tape is silver.", "Welcome to flavortown!",
        "I get enough exercise pushing my luck.", "Unicorns ARE real, theyâ€™re just fat, grey, and we call them rhinos.",
        "Iâ€™d like to help you out. Which way did you come in?", "There are too many dogs in your inventory.",
        "Careful man, there's a beverage present.", "Fool me once, fool me twice, fool me chicken soup with rice.",
        "60% of the time, it works EVERYTIME!", "Imagine how is touch the sky.",
        "I can't find my keyboard, it must be here somewhereâ€¦", "The quick brown fox jumped over the lazy dog.",
        "No, this is Patrick.", "My spirit animal will eat yours.", "Roses are red, violets are blue, lmao XD UWU!",
        "You can't run away from all your problemsâ€¦\n            Not when they have ender pearls.",
        "[!] bite hazard [!]", "How are you doing today Bob/Steve/Kyle?", "Only uses 69% CPU!!!",
        "oops wrong Minecraft", "Fallout 4 is TRUE gabage", "Supply + Demand :\\", "Y'know Aimlabs is freeâ€¦ right??",
        "Mad-a-gas-carâ€¦ 'cause I couldn't afford a Teslaâ€¦", "it really is that shrimple!",
        "This basement is a true treasure trove!", "Is it a gallon of pickles, or a gallon jar of pickles?",
        "Have you tried closing it and re-opening it?"
    ]

    if crash:
        exp = re.sub(r'\s+',' ',splashes[randrange(len(splashes))]).strip()
        return f'"{exp}"'

    if headless: session_splash = f"â€œ{splashes[randrange(len(splashes))]}â€"
    else:        session_splash = f"â€œâ€ˆ{splashes[randrange(len(splashes))]}â€ˆâ€"


# </editor-fold>



# ---------------------------------------------- Helper Functions ------------------------------------------------------
# <editor-fold desc="Helper Functions">

# Literally just a 'threading.Timer', but with daemon set by default
class dTimer(threading.Timer):
    def __init__(self, interval, function, args=None, kwargs=None):
        super().__init__(interval, function, args, kwargs)
        self.daemon = True


# Removes invalid characters from a filename
def sanitize_name(value, addon=False) -> str:

    if value == 'WorldEdit for Bukkit':
        return 'WorldEdit'

    value = '-'.join([v.strip() for v in value.split(":")])
    value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore').decode('ascii')
    value = re.sub(r'[^\'\w\s-]', '', value)
    return re.sub(r'[-\s]+', '-', value).strip('-_')


# Create random string of characters
def gen_rstring(size: int) -> str:
    return ''.join(choices(string.ascii_uppercase + string.ascii_lowercase, k=size))


# Returns full error into a string for logging
def format_traceback(exception: Exception) -> str:
    last_trace = traceback.format_exc()
    return f'{exception}\nTraceback:\n{last_trace}'


# Format date string to be cross-platform compatible
def fmt_date(date_string: str) -> str:
    if os_name == 'windows': return date_string
    else: return date_string.replace('%#','%-')


# Returns current formatted time
def format_now() -> str:
    return dt.now().strftime(fmt_date("%#I:%M:%S %p"))


# Converts between HEX and RGB decimal colors
def convert_color(color: str or tuple) -> dict:

    # HEX
    if isinstance(color, str):
        color = color.replace("#", "")
        if len(color) == 6:
            split_color = (color[0:2], color[2:4], color[4:6])
        else:
            split_color = (color[0]*2, color[1]*2, color[2]*2)

        new_color = [0, 0, 0]

        for x, item in enumerate(split_color):
            item = round(int(item, 16) / 255, 3)
            new_color[x] = int(item) if item in [0, 1] else item

        new_color.append(1)

        return {'hex': '#'+''.join(split_color).upper(), 'rgb': tuple(new_color)}


    # RGB decimal
    else:

        new_color = "#"

        for item in color[0:3]:
            x = str(hex(round(item * 255)).split("0x")[1]).upper()
            x = f"0{x}" if len(x) == 1 else "FF" if len(x) > 2 else x
            new_color += x

        rgb_color = list(color[0:3])
        rgb_color.append(1)

        return {'hex': new_color, 'rgb': tuple(rgb_color)}


# Returns modified color tuple or HEX string
def brighten_color(color: tuple or str, amount: float) -> tuple or str:

    # If HEX, convert to decimal RGB
    hex_input = False
    if isinstance(color, str):
        color = convert_color(color)['rgb']
        hex_input = True


    color = list(color)

    for x, y in enumerate(color):
        if x < 3:
            new_amount = y + amount
            new_amount = 1 if new_amount > 1 else 0 if new_amount < 0 else new_amount
            color[x] = new_amount

    return convert_color(color)['hex'] if hex_input else tuple(color)


# Returns similarity of strings with a metric of 0-1
def similarity(a: str, b: str) -> float:
    return round(SequenceMatcher(None, a, b).ratio(), 2)


# Rotate an array
# (int) rotation: 'x' is forwards, '-x' is backwards
def rotate_array(array: list, rotation: int) -> list:

    if rotation > 0:
        for x in range(0, rotation):
            array.insert(0, array.pop(-1))
    else:
        for x in range(rotation, 0):
            array.append(array.pop(0))

    return array


# Allows parsing of any OS path style
def cross_platform_path(path, depth=1):
    """
    Returns the last `depth` components of the given path.

    For Unix-style paths:
      - Only forward slashes ("/") are considered true directory separators.
      - Backslashes are used to escape characters (e.g. spaces) and are unescaped in the result.
      - If the original path is absolute (starts with '/'), the returned value will also be absolute.

    For Windows-style paths:
      - Both backslashes ("\") and forward slashes ("/") are treated as separators.
      - No unescaping is performed.

    If depth is greater than the available number of components,
    the original path is returned.

    Parameters:
      path (str): The file path.
      depth (int): The number of path components (from the right) to return (default is 1).

    Returns:
      str: The resulting subpath.
    """
    if depth < 1:
        raise ValueError("depth must be >= 1")

    def sanitize(text: str):
        return text.lstrip('/').lstrip('\\')

    # Remove any trailing separators to avoid an empty final component.
    path = re.sub(r'[\\/]+$', '', path)

    # Detect Windows-style paths:
    # - They often start with a drive letter (e.g., "C:\...")
    # - Or they contain backslashes and no forward slashes.
    if re.match(r'^[A-Za-z]:', path) or ('\\' in path and '/' not in path):
        # Split on one or more of either separator.
        parts = re.split(r'[\\/]+', path)
        # If the requested depth is more than available parts, return the original path.
        if depth >= len(parts):
            return sanitize(path)
        # Join the last `depth` parts with the Windows separator.
        return sanitize('\\'.join(parts[-depth:]))
    else:
        # Unix-style path.
        # In Unix, the only true separator is "/"; backslashes are escapes.
        is_absolute = path.startswith('/')
        # Split on "/" (ignoring empty strings which can occur if the path is absolute)
        parts = [p for p in path.split('/') if p]
        if depth > len(parts):
            # If depth is more than available, return the original path.
            return sanitize(path)
        # Grab the last `depth` components.
        selected_parts = parts[-depth:]
        # Unescape any escaped characters in each component (e.g. turn "\ " into " ").
        selected_parts = [re.sub(r'\\(.)', r'\1', comp) for comp in selected_parts]
        result = '/'.join(selected_parts)
        if is_absolute:
            result = '/' + result
        return sanitize(result)


# CTRL + Backspace function
def control_backspace(text, index):

    # Split up text into parts
    start = text[:index].strip()
    end = text[index:]

    if " " not in start:
        new_text = ""
    else:
        new_text = start.rsplit(" ", 1)[0]

    # Add space between concatenated blocks if one does not exist
    try:
        if new_text[-1] != " " and not end:
            new_text += " "

        elif new_text[-1] != " " and end[0] != " ":
            new_text += " "

    except IndexError:
        pass

    # Return edited text
    final_text = new_text + end
    new_index = len(text) - len(final_text)
    return final_text, new_index


# </editor-fold>



# ---------------------------------------------- Server Functions ------------------------------------------------------
# <editor-fold desc="Server Functions">

# Minecraft color codes
color_table: dict[str, str] = {
    'Â§0': '#000000', 'Â§1': '#0000AA', 'Â§2': '#00AA00', 'Â§3': '#00AAAA',
    'Â§4': '#AA0000', 'Â§5': '#AA00AA', 'Â§6': '#FFAA00', 'Â§7': '#AAAAAA',
    'Â§8': '#555555', 'Â§9': '#5555FF', 'Â§a': '#55FF55', 'Â§b': '#55FFFF',
    'Â§c': '#FF5555', 'Â§d': '#FF55FF', 'Â§e': '#FFFF55', 'Â§f': '#FFFFFF'
}

# Oldest version that supports files like "ops.json" format
json_format_floor:      str = "1.7.6"


# Verify portable java is available in '.buddyservers\Tools', if not install it
# '*._pct' is for local installation progress bars
modern_pct:   int = 0
lts_pct:      int = 0
legacy_pct:   int = 0

# Prevent running or importing servers while these are blank
java_executable: dict[str, str] = {
    "modern": None,
    "legacy": None,
    "lts":    None,
    "jar":    None
}
def java_check(progress_func=None):
    from source.core.server.foundry import new_server_info

    # If telepath, check if Java is installed remotely
    telepath_data = None
    if server_manager.current_server:
        telepath_data = server_manager.current_server._telepath_data

    try:
        if not telepath_data and new_server_info['_telepath_data']:
            telepath_data = new_server_info['_telepath_data']
    except KeyError:
        pass

    if telepath_data:
        response = api_manager.request(
            endpoint = '/main/java_check',
            host = telepath_data['host'],
            port = telepath_data['port'],
            args = {}
        )
        if progress_func and response:
            progress_func(100)
        return response


    global java_executable, modern_pct, lts_pct, legacy_pct
    max_retries = 3
    retries = 0
    modern_version = 21
    send_log('java_check', f"validating Java installations...", 'info')

    java_url = {
        'windows': {
            "modern": f"https://download.oracle.com/java/{modern_version}/latest/jdk-{modern_version}_windows-x64_bin.zip",
            "lts": f"https://download.oracle.com/java/17/archive/jdk-17.0.12_windows-x64_bin.zip",
            "legacy": "https://javadl.oracle.com/webapps/download/GetFile/1.8.0_331-b09/165374ff4ea84ef0bbd821706e29b123/windows-i586/jre-8u331-windows-x64.tar.gz"
        },
        'linux': {
            "modern": f"https://download.oracle.com/java/{modern_version}/latest/jdk-{modern_version}_linux-x64_bin.tar.gz",
            "lts": f"https://download.oracle.com/java/17/archive/jdk-17.0.12_linux-x64_bin.tar.gz",
            "legacy": "https://javadl.oracle.com/webapps/download/GetFile/1.8.0_331-b09/165374ff4ea84ef0bbd821706e29b123/linux-i586/jre-8u331-linux-x64.tar.gz"
        },
        'linux-arm64': {
            "modern": f"https://download.oracle.com/java/{modern_version}/latest/jdk-{modern_version}_linux-aarch64_bin.tar.gz",
            "lts": f"https://download.oracle.com/java/17/archive/jdk-17.0.12_linux-aarch64_bin.tar.gz",
            "legacy": "https://javadl.oracle.com/webapps/download/GetFile/1.8.0_281-b09/89d678f2be164786b292527658ca1605/linux-i586/jdk-8u281-linux-aarch64.tar.gz"
        },
        'macos': {
            "modern": f"https://download.oracle.com/java/{modern_version}/latest/jdk-{modern_version}_macos-x64_bin.tar.gz",
            "lts": f"https://download.oracle.com/java/17/archive/jdk-17.0.12_macos-x64_bin.tar.gz",
            "legacy": "https://javadl.oracle.com/webapps/download/GetFile/1.8.0_331-b09/165374ff4ea84ef0bbd821706e29b123/unix-i586/jre-8u331-macosx-x64.tar.gz"
        }
    }

    while not (java_executable['modern'] and java_executable['lts'] and java_executable['legacy']):

        # Delete downloads folder
        safe_delete(paths.downloads)

        # If max_retries exceeded, give up
        if retries > max_retries:
            send_log('java_check', f"Java failed to download or install", 'error')
            return False

        # Check if installations function before doing anything
        if os.path.exists(os.path.abspath(paths.java)):

            # Gather paths to Java installed internally
            if os_name == 'macos':
                modern_path = os.path.join(paths.java, 'modern', 'Contents', 'Home', 'bin', 'java')
                lts_path    = os.path.join(paths.java, 'lts', 'Contents', 'Home', 'bin', 'java')
                legacy_path = os.path.join(paths.java, 'legacy', 'Contents', 'Home', 'bin', 'java')
                jar_path    = os.path.join(paths.tools, 'java', 'modern', 'Contents', 'Home', 'bin', 'jar')

            else:
                modern_path = os.path.join(paths.java, 'modern', 'bin', 'java.exe' if os_name == "windows" else 'java')
                lts_path    = os.path.join(paths.java, 'lts', 'bin', 'java.exe'    if os_name == "windows" else 'java')
                legacy_path = os.path.join(paths.java, 'legacy', 'bin', 'java.exe' if os_name == "windows" else 'java')
                jar_path    = os.path.join(paths.java, 'modern', 'bin', 'jar.exe'  if os_name == "windows" else 'jar')


            if (run_proc(f'"{os.path.abspath(modern_path)}" --version') == 0) and (run_proc(f'"{os.path.abspath(lts_path)}" --version') == 0) and (run_proc(f'"{os.path.abspath(legacy_path)}" -version') == 0):

                # Check for appropriate modern version
                if is_docker or run_proc(f'"{os.path.abspath(modern_path)}" --version', return_text=True).startswith(f'java {modern_version}.'):

                    java_executable = {
                        "modern": str(os.path.abspath(modern_path)),
                        "lts": str(os.path.abspath(lts_path)),
                        "legacy": str(os.path.abspath(legacy_path)),
                        "jar": str(os.path.abspath(jar_path))
                    }

                    send_log('java_check', f"valid Java installations detected", 'info')

                    if progress_func:
                        progress_func(100)

                    return True


        # If valid java installs are not detected, install them to '.buddyservers\Tools'
        if not (java_executable['modern'] and java_executable['lts'] and java_executable['legacy']):

            send_log('java_check', f"Java is not detected, installing...", 'info')


            # On Docker, use apk to install Java instead
            if is_docker:
                run_proc('apk add openjdk21 openjdk17 openjdk8', True)
                folder_check(paths.java)
                try:
                    move('/usr/lib/jvm/java-21-openjdk', os.path.join(paths.java, 'modern'))
                    move('/usr/lib/jvm/java-17-openjdk', os.path.join(paths.java, 'lts'))
                    move('/usr/lib/jvm/java-1.8-openjdk', os.path.join(paths.java, 'legacy'))
                except: pass
                continue



            # Download java versions in threadpool:
            folder_check(paths.downloads)

            modern_filename = f'modern-java.{os.path.basename(java_url[os_name]["modern"]).split(".", 1)[1]}'
            lts_filename    = f'lts-java.{os.path.basename(java_url[os_name]["lts"]).split(".", 1)[1]}'
            legacy_filename = f'legacy-java.{os.path.basename(java_url[os_name]["legacy"]).split(".", 1)[1]}'

            # Use timer and combined function to get total percentage of both installs
            modern_pct = 0
            lts_pct = 0
            legacy_pct = 0

            def avg_total(*args):
                global modern_pct, legacy_pct
                while True:
                    progress_func(round((modern_pct + lts_pct + legacy_pct) / 3))
                    time.sleep(0.2)
                    if (modern_pct >= 100 and lts_pct >= 100 and legacy_pct >= 100):
                        break

            if progress_func:
                timer = dTimer(0, function=avg_total)
                timer.start()


            # Detect if running on ARM
            if os_name == 'linux' and is_arm:
                os_download = 'linux-arm64'
            else:
                os_download = os_name


            with ThreadPoolExecutor(max_workers=2) as pool:

                def hook1(a, b, c):
                    global modern_pct
                    modern_pct = round(100 * a * b / c)

                def hook2(a, b, c):
                    global lts_pct
                    lts_pct = round(100 * a * b / c)

                def hook3(a, b, c):
                    global legacy_pct
                    legacy_pct = round(100 * a * b / c)

                pool.map(
                    download_url,
                    [java_url[os_download]['modern'], java_url[os_download]['lts'], java_url[os_download]['legacy']],
                    [modern_filename, lts_filename, legacy_filename],
                    [paths.downloads, paths.downloads, paths.downloads],
                    [hook1 if progress_func else None, hook2 if progress_func else None, hook3 if progress_func else None]
                )

            if progress_func:
                timer.cancel()

            # Install java by extracting the files to their respective folder
            modern_path = os.path.join(paths.java, 'modern')
            lts_path = os.path.join(paths.java, 'lts')
            legacy_path = os.path.join(paths.java, 'legacy')

            safe_delete(modern_path)
            safe_delete(lts_path)
            safe_delete(legacy_path)

            with ThreadPoolExecutor(max_workers=2) as pool:
                pool.map(
                    extract_archive,
                    [os.path.join(paths.downloads, modern_filename), os.path.join(paths.downloads, lts_filename), os.path.join(paths.downloads, legacy_filename)],
                    [modern_path, lts_path, legacy_path],
                    [True, True, True]
                )

            retries += 1

    else:
        if progress_func:
            progress_func(100)

        return True


# Comparison tool for Minecraft version strings
def version_check(version_a: str, comparator: str, version_b: str) -> bool:
    def parse_version(version):
        version = version.lower()
        # Split the version into parts, including handling pre-release (-preX)
        if "-pre" in version:
            main_version, pre_release = version.split("-pre", 1)
            parts = main_version.split(".") + [f"-{pre_release}"]
        else:
            parts = version.split(".")

        parsed = []
        for part in parts:
            # Handle pre-release identifiers
            if part.startswith("-pre"):
                parsed.append(-1000)  # Pre-release marker, always less than normal versions
                part = part.replace("-pre", "")
                if part.isdigit():
                    parsed.append(int(part))
            elif "a" in part:
                parsed.append(-2)  # 'a' is less than 'b'
                part = part.replace("a", "")
            elif "b" in part:
                parsed.append(-1)  # 'b' is less than normal numbers
                part = part.replace("b", "")
            if part.isdigit():
                parsed.append(int(part))
        return tuple(parsed)

    try:
        # Parse both versions into comparable tuples
        parsed_a = parse_version(version_a)
        parsed_b = parse_version(version_b)

        # Perform the comparison
        if comparator == ">":
            return parsed_a > parsed_b
        elif comparator == ">=":
            return parsed_a >= parsed_b
        elif comparator == "<":
            return parsed_a < parsed_b
        elif comparator == "<=":
            return parsed_a <= parsed_b
        elif comparator == "==":
            return parsed_a == parsed_b
        else:
            raise ValueError(f"Invalid comparator: {comparator}")
    except Exception as e:
        return False


# Check if level is compatible with server version
# Returns (True, "") if world is compatible, else (False, "world_version"). (False, None) if world has an unknown version
def check_world_version(world_path: str, server_version: str) -> tuple[bool, str or None]:

    world_path = os.path.abspath(world_path)
    level_dat = os.path.join(world_path, "level.dat")
    cache_file = os.path.join(paths.cache, "data-version-db.json")

    # Only check data version if world and cache file exist
    if os.path.isdir(world_path) and os.path.isfile(cache_file):
        if os.path.isfile(level_dat):
            try:
                nbt_file = nbt.NBTFile(level_dat, 'rb')
                world_data_version = str(nbt_file["Data"]["DataVersion"].value)

            # Return if old version with unknown type
            except KeyError or IndexError:
                return (False, None)

            # If world has data version
            else:

                with open(cache_file, 'r', encoding='utf-8', errors='ignore') as f:
                    cache_file = json.load(f)

                try:
                    world_version = ([item for item in cache_file.items() if world_data_version == item[1]][0])
                # Accept as valid if world could not be found, it's probably too new
                except IndexError:
                    return (True, None)
                try:
                    server_version = (server_version, cache_file[server_version])
                except:
                    server_version = (server_version, None)

                # If world newer than intended server, prompt user with error
                if version_check(world_version[0], ">", server_version[0]) and ('w' not in server_version[0]):
                    return (False, world_version[0])

                elif server_version[1]:
                    if int(world_version[1]) > int(server_version[1]):
                        return (False, world_version[0])

    # World is compatible, or otherwise can't check
    return (True, "")


# </editor-fold>



# --------------------------------------------- Telepath Functions -----------------------------------------------------
# <editor-fold desc="Telepath Functions">

# Global instance of the Telepath API manager (used for server & client-side)
api_manager: 'core.telepath.TelepathManager' = None

# Set by the corresponding UI to be called from helper methods here
telepath_disconnect:                callable = None
telepath_banner:                    callable = None
telepath_pair:     'ui.desktop.TelepathPair' = None

# This whitelist is for restricting downloadable content from clients
telepath_download_whitelist:       dict = {
    'paths': [paths.servers, paths.scripts, paths.backups],
    'names': ['.ams', '.amb', 'server-icon.png', *[f'.{ext}' for ext in valid_config_formats]]
}


# Downloads a file to a Telepath session --> destination path
def telepath_download(telepath_data: dict, path: str, destination=paths.downloads, rename='') -> str:
    if not api_manager:
        return False

    host = telepath_data['host']
    port = telepath_data['port']
    url = f"http://{host}:{port}/main/download_file?file={quote(path)}"

    send_log('telepath_download', f"downloading '{url}' to '{destination}'...")
    session = api_manager._get_session(host, port)
    request = lambda: session.post(url, headers=api_manager._get_headers(host), stream=True)
    data = api_manager._retry_wrapper(host, port, request)

    # Save if the request was successful
    if data and data.status_code == 200:

        # File name input validation
        file_name = os.path.basename(rename if rename else path)
        if '/' in file_name:
            file_name = file_name.rsplit('/', 1)[-1]
        elif '\\' in file_name:
            file_name = file_name.rsplit('\\', 1)[-1]

        final_path = os.path.join(destination, file_name)
        folder_check(destination)

        with open(final_path, 'wb') as file:
            for chunk in data.iter_content(chunk_size=8192):
                file.write(chunk)

        send_log('telepath_download', f"downloaded '{url}' to '{final_path}'")
        return final_path

    else: send_log('telepath_download', f"failed to download '{url}'", 'error')


# Uploads a file or directory to a Telepath session of BuddyServers -> destination path
def telepath_upload(telepath_data: dict, path: str) -> Any:
    if not api_manager:
        return False

    if os.path.exists(path):
        is_dir = False

        # If path is a directory, compress to tmp and use the archive instead
        if os.path.isdir(path):
            is_dir = True
            path = create_archive(path, paths.temp, 'tar')

        host = telepath_data['host']
        port = telepath_data['port']
        url = f"http://{host}:{port}/main/upload_file?is_dir={is_dir}"

        send_log('telepath_upload', f"uploading '{path}' to '{url}'...")
        session = api_manager._get_session(host, port)
        request = lambda: session.post(url, headers=api_manager._get_headers(host, True), files={'file': open(path, 'rb')})
        data = api_manager._retry_wrapper(host, port, request)

        if data: return data.json()
        else: send_log('telepath_upload', f"failed to upload to '{url}'", 'error')


# Delete all files in Telepath uploads remotely (this is executed from a client)
def clear_uploads() -> bool:
    safe_delete(paths.uploads)
    send_log('clear_uploads', f"cleared Telepath uploads in '{paths.uploads}'")
    return not os.path.exists(paths.uploads)


# Gets a variable from this module, remotely if telepath_data is specified
def get_remote_var(var: str, telepath_data: dict = {}) -> Any:
    if telepath_data:
        return api_manager.request(
            endpoint = '/main/get_remote_var',
            host = telepath_data['host'],
            port = telepath_data['port'],
            args = {'var': var}
        )

    else:

        # If it's a sub-attribute
        if '.' in var: root, attr = [i.strip() for i in var.split('.', 1)]
        else: root = var; attr = None

        # Get root value
        try: value = getattr(sys.modules[__name__], root)
        except Exception as e: value = None; print(format_traceback(e))

        if attr:
            try: value = getattr(value, attr)
            except: value = None

        return value


# Returns to Telepath clients that this instance is set to 'ignore_close'
def telepath_busy() -> bool:
    return ignore_close and server_manager.remote_servers


# Removes invalid characters for a Telepath nickname
def format_nickname(nickname) -> str:
    formatted = re.sub('[^a-zA-Z0-9 _().-]', '', nickname.lower())
    formatted = re.sub(r'[\s-]+', '-', formatted)

    # Remove leading and trailing hyphens
    formatted = formatted.strip('-')

    # If the length of the string is greater than 20 characters
    if len(formatted) > 20 and '-' in formatted:
        formatted = formatted.split('-', 1)[0]

    return formatted


# Helper method for sorting and retrieving data via the API
def sync_attr(self, name):
    if name != '__all__':
        return getattr(self, name)
    else:
        blacklist = ['addon', 'backup', 'acl', 'script_manager', 'script_object', 'run_data', 'taskbar', '_manager']
        def allow(x):
            return ((not callable(getattr(self, x))) and (str(x) not in blacklist) and (not str(x).endswith('__')))
        return {a: getattr(self, a) for a in dir(self) if allow(a)}


# </editor-fold>



# -------------------------------------------- Global Config Manager ---------------------------------------------------

# Handles all operations when writing/reading from global config. Adding attributes changes the config file
class ConfigManager():

    # Internal log wrapper
    def _send_log(self, message: str, level: str = None):
        return send_log(self.__class__.__name__, message, level)

    def __init__(self):
        self._path = os.path.join(paths.config, 'app-config.json')
        self._defaults = self._init_defaults()
        self._data = Munch({})

        # Initialize default values
        if os.path.exists(paths.app_folder):
            if self.load_config(): self._send_log(f"initialized ConfigManager successfully", 'info')
            else:                  self._send_log(f"failed to initialize ConfigManager", 'error')

    # Specify default values
    @staticmethod
    def _init_defaults():
        defaults = Munch({})
        defaults.fullscreen        = False    # Stores if the desktop app was maximized or not
        defaults.geometry          = {}       # Stores the last window position & size of the desktop UI
        defaults.auto_update       = True     # Whether BuddyServers will prompt to auto-update on open
        defaults.locale            = None     # UI language (should sync with system if unset)
        defaults.master_volume     = 100      # UI sound volume (int: 0-100, 0 will mute entirely)
        defaults.sponsor_reminder  = None     # Animates the heart on the splash screen once a month
        defaults.discord_presence  = True     # Shares the app state through Discord Rich Presence
        defaults.prompt_feedback   = True     # First server launched ever will prompt for anonymous feedback
        defaults.enable_ip_lookup  = True     # Public IP display in the console if port forwarded, and geolocation resolution in the ACL Manager
        defaults.telepath_settings = {
            'enable-api':   False,            # Globally enables Telepath remote access
            'api-host':     "0.0.0.0",        # NIC to broadcast Telepath access (default: all interfaces)
            'api-port':     7001,             # Port to broadcast Telepath traffic
            'show-banners': True,             # Allow banners to be displayed in the UI from remote actions
            'id_hash':      None
        }
        defaults.ide_settings = {
            'fullscreen':   False,            # Stores if the desktop amscript IDE was maximized or not
            'font-size':    15,               # Stores the configured font size of the IDE
            'geometry':     {}                # Stores the last window position & size of the IDE
        }
        return defaults

    def __setattr__(self, key, value):
        if key.startswith('_'):
            super().__setattr__(key, value)
        elif key not in self._defaults:
            raise AttributeError(f"'{self.__class__.__name__}' does not support '{key}'")
        else:
            self._data[key] = value
            self.save_config()

    def __getattr__(self, key):
        if key == '__setstate__':
            self._data = Munch({})
            self._path = os.path.join(paths.config, 'app-config.json')
            self._defaults = self._init_defaults()
            self.load_config()

        if key in self._data:

            # First, fix empty dictionaries
            if isinstance(self._data[key], dict):
                for k, v in self._defaults[key].items():
                    if k not in self._data[key]:
                        self._data[key][k] = v

            # Then return the value
            return self._data[key]

        elif key in self._defaults:
            return self._defaults[key]
        raise AttributeError(f"'{self.__class__.__name__}' object has no attribute '{key}'")


    def load_config(self):
        if os.path.exists(self._path):
            with open(self._path, 'r', encoding='utf-8', errors='ignore') as file:
                try:
                    self._data = json.loads(file.read().replace('ide-settings', 'ide_settings'))
                    self._send_log(f"successfully loaded global configuration from '{self._path}'")
                    return True
                except json.decoder.JSONDecodeError:
                    pass

        self._send_log('failed to read global configuration, resetting...', 'error')
        self.reset()

    def save_config(self):
        try:
            folder_check(os.path.dirname(self._path))
            with open(self._path, 'w') as file:
                json.dump(self._data, file, indent=2)

        except Exception as e: self._send_log(f"failed to save global configuration to '{self._path}': {format_traceback(e)}", 'error')
        else:                  self._send_log(f"successfully saved global configuration to '{self._path}'")

    def reset(self):
        if os.path.exists(self._path): os.remove(self._path)
        self._data = self._defaults.copy()
        self.save_config()

# Global config manager
app_config: ConfigManager = ConfigManager()



# --------------------------------------------- Global Search Functions ------------------------------------------------

# Generates content for all global searches
class SearchManager():

    # Internal log wrapper
    def _send_log(self, message: str, level: str = None):
        return send_log(self.__class__.__name__, message, level)

    def get_server_list(self):
        if server_manager.menu_view_list:
            return {s._view_name: s._telepath_data for s in server_manager.menu_view_list}
        else:
            return {s: None for s in server_manager.create_server_list()}

    def __init__(self):

        # Used to contain attributes of pages
        class ScreenObject():
            def __init__(self, name: str, screen_id: str, options: list or staticmethod, helper_keywords=[]):
                self.id = screen_id
                self.name = name
                self.options = options
                self.helper_keywords = helper_keywords
                self.score = 0

        self.guide_tree = {}
        self.options_tree = {

            'MainMenu': [
                ScreenObject('Home', 'MainMenuScreen', {'Create a new server': 'CreateServerModeScreen', 'Import a server': 'ServerImportScreen', 'Install a modpack': 'ServerImportModpackScreen', 'Create from a template': 'CreateServerTemplateScreen'}, ['addonpack', 'modpack', 'import modpack', 'import', 'create', 'new', 'instant', 'template']),
                ScreenObject('Server Manager', 'ServerManagerScreen', self.get_server_list),
                ScreenObject('Settings', 'AppSettingsScreen', {'Update BuddyServers': None, 'View changelog': f'{project_repo}/releases/latest', 'Change language': 'ChangeLocaleScreen', 'Telepath': 'TelepathManagerScreen'}, ['telepath', 'locale', 'language', 'move app', 'discord', 'reset', 'audio', 'volume', 'sound']),
            ],

            'CreateServer': [
                ScreenObject('Create Server (Step 1)', 'CreateServerNameScreen', {'Server Name': None}),
                ScreenObject('Create Server (Step 2)', 'CreateServerTypeScreen', {'Select Vanilla': None, 'Select Paper': None, 'Select Purpur': None, 'Select Fabric': None, 'Select CraftBukkit': None, 'Select Forge': None, 'Select Spigot': None}),
                ScreenObject('Create Server (Step 3)', 'CreateServerVersionScreen', {'Type in version': None}),
                ScreenObject('Create Server (Step 4)', 'CreateServerWorldScreen', {'Browse for a world': None, 'Type in seed': None, 'Select world type': None}),
                ScreenObject('Create Server (Step 5)', 'CreateServerNetworkScreen', {'Specify IP/port': None, 'Type in Message Of The Day': None, 'Configure Access Control': 'CreateServerAclScreen'}),
                ScreenObject('Create Server (Access Control)', 'CreateServerAclScreen', {'Configure bans': None, 'Configure operators': None, 'Configure the whitelist': None}, ['player', 'user', 'ban', 'white', 'op', 'rule', 'ip', 'acl', 'access control']),
                ScreenObject('Create Server (Add-on Manager)', 'CreateServerAddonScreen', {'Download add-ons': 'CreateServerAddonSearchScreen', 'Import add-ons': None, 'Toggle add-on state': None}, ['mod', 'plugin', 'addon', 'extension']),
                ScreenObject('Create Server (Step 6)', 'CreateServerOptionsScreen', {'Change gamemode': None, 'Change difficulty': None, 'Specify maximum players': None, 'Enable spawn protection': None, 'Configure gamerules': None, 'Specify randomTickSpeed': None, 'Enable Bedrock support': None}),
                ScreenObject('Create Server (Step 7)', 'CreateServerReviewScreen', {'Review & create server': None})
            ],

            'ServerImport': [
                ScreenObject('Import Server', 'ServerImportScreen', {'Import a server folder': None, 'Import a BuddyServers back-up': None, 'Import a Modpack': None, 'Download a Modpack': None}),
            ],

            'Server': [
                ScreenObject('Server Manager', 'ServerViewScreen', {'Launch server': None, 'Stop server': None, 'Restart server': None, 'Enter console commands': None}),
                ScreenObject('Back-up Manager', 'ServerBackupScreen', {'Save a back-up now': None, 'Restore from a back-up': 'ServerBackupRestoreScreen', 'Enable automatic back-ups': None, 'Specify maximum back-ups': None, 'Open back-up directory': None, 'Migrate back-up directory': None, 'Clone this server': 'ServerCloneScreen'}, ['backup', 'revert', 'snapshot', 'restore', 'save', 'clone']),
                ScreenObject('Access Control', 'ServerAclScreen', {'Configure bans': None, 'Configure operators': None, 'Configure the whitelist': None}, ['player', 'user', 'ban', 'white', 'op', 'rule', 'ip', 'acl', 'access control']),
                ScreenObject('Add-on Manager', 'ServerAddonScreen', {'Download add-ons': 'ServerAddonSearchScreen', 'Import add-ons': None, 'Toggle add-on state': None, 'Update add-ons': None}, ['mod', 'plugin', 'addon', 'extension']),
                ScreenObject('Script Manager', 'ServerAmscriptScreen', {'Download scripts': 'ServerAmscriptSearchScreen', 'Import scripts': None, 'Create a new script': 'CreateAmscriptScreen', 'Edit a script': None, 'Open script directory': None}, ['amscript', 'script', 'ide', 'develop']),
                ScreenObject('Server Settings', 'ServerSettingsScreen', {"Edit configuration files": 'ServerConfigScreen', "Edit 'server.properties'": None, 'Open server directory': None, 'Specify memory usage': None, 'Change MOTD': None, 'Specify IP/port': None, 'Change launch flags': None, 'Enable proxy (playit)': None, 'Install proxy (playit)': None, 'Enable Bedrock support': None, 'Enable automatic updates': None, 'Update this server': None, "Change 'server.jar'": 'MigrateServerTypeScreen', 'Rename this server': None, 'Change world file': 'ServerWorldScreen', 'Delete this server': None}, ['ram', 'memory', 'server.properties', 'properties', 'rename', 'delete', 'bedrock', 'proxy', 'ngrok', 'playit', 'update', 'jvm', 'motd', 'yml', 'config'])
            ]
        }

    # Cache the guides to a .json file
    def cache_pages(self):
        if not app_online:
            self._send_log(f"failed to fully initialize SearchManager: {app_title} is offline", 'error')
            return False

        def get_html_contents(url: str):
            while True:
                req = requests.get(url)
                if req.status_code == 200:
                    break
                else:
                    time.sleep(3)

            return BeautifulSoup(req.content, features='html.parser')

        cache_file = os.path.join(paths.cache, 'guide-cache.json')
        cache_data = {}

        # If cache file exists, load data from there instead
        if os.path.exists(cache_file):
            with open(cache_file, 'r', encoding='utf-8', errors='ignore') as f:
                self.guide_tree = json.loads(f.read())
                self._send_log(f"initialized SearchManager from cache in '{cache_file}'", 'info')
                return True

        # If not, scrape the website
        base_url = "https://github.com/ShuvoSync/BuddyServers/wiki"
        content = get_html_contents(base_url)

        for a in content.find_all('a', class_="portfolio-hover-item"):

            sub_url = base_url + a.get('href').replace('guides/', '')
            title = a.get_text().strip()

            guide = get_html_contents(sub_url)
            time.sleep(1)

            # Clean-up guide by removing unnecessary elements
            for tag in guide("div", id='toc'):
                tag.decompose()
            for tag in guide("section", id='itemPagination'):
                tag.decompose()
            for tag in guide("section", class_='page-section'):
                if '<  guides' in tag.get_text() or 'help@buddyservers.com' in tag.get_text():
                    tag.decompose()

            # Format specific tags in a custom way
            for tag in guide("code"):
                add_space = tag.text[-1] == ' '
                tag.replace_with(f'`{tag.text.strip()}`{" " if add_space else ""}')

            for tag in guide("a"):
                try:
                    href = tag.get('href')
                    if href:
                        if href.startswith('/'):
                            href = f'https://github.com/ShuvoSync/BuddyServers/wiki{href}'

                        if href.endswith('.png') or href.endswith('.jpg'):
                            new_href = requests.get(href, allow_redirects=True).history[-1].headers['location']
                            time.sleep(1)
                            tag.replace_with(BeautifulSoup(f'<img src="{new_href}">', 'html.parser').img)
                            continue

                        tag.replace_with(f'[{tag.text}](<{href}>)')
                except:
                    pass

            # Organize page contents into a dictionary of headers and paragraphs
            page_content = {}
            images = {}
            last = None
            last_header = ''
            header_list = ['h1', 'h2', 'h3']
            for element in guide.find_all():
                text = element.text.strip()

                accordion_header = 'accordion-item__title' in element.get('class', []) and element.name == 'span'

                if element.name in ['p', 'ul', 'img'] or element.name in header_list or accordion_header:
                    if len(element.text) > 10000:
                        continue

                    if last:
                        if last.name in header_list and element.name in header_list:
                            continue

                    # Format lists
                    if element.name == 'ul':
                        text = '\n'.join([f'- {l.text.strip()}' for l in element.find_all('li') if l.text.strip()])
                    elif element.name == 'li' or element.parent.name == 'li':
                        continue

                    # Format images
                    if element.name == 'img':
                        try:
                            text = f"[â €]({element.get('src')})"
                            images[last_header].append(text)
                        except:
                            pass
                        continue

                    last = element

                    # Ignore certain headers
                    if ('controls' == text.lower() or 'some notable features include' in text.lower()):
                        text = f"## {text}"

                    # Add header
                    elif element.name in header_list or accordion_header:
                        last_header = text.lower()
                        page_content[last_header] = ''
                        images[last_header] = []
                        continue

                    page_content[last_header] += re.sub(r'\n\n+', '\n\n', text) + '\n'

            # Format text to read better
            for header, content in page_content.items():
                content = re.sub(r'\.(?=[A-Z])', '.\n\n', content)
                content = re.sub(r'(\n+Note:  )(.*)(\n+)', lambda x: f'\n\n> *Note:*  **{x.group(2)}**\n\n', f'\n{content}\n').strip()
                content = re.sub(r'(?<=(\w|\d|\.|\?|\!))(\n)(?=(\w|\d|\.|\?|\!))', '\n\n', content).strip()
                content = content.replace('permissions**\n\n!`buddyservers --launch "Server 1, Server 2"`', 'permissions! `buddyservers --launch "Server 1, Server 2"`**')
                content = content.replace('`java.lang.**\n\nOutOfMemoryError: Java heap space`', '`java.lang.OutOfMemoryError: Java heap space`**')
                if header in images:
                    content += ' '.join(list(set(images[header])))

                # Remove empty data
                if not content.strip():
                    del page_content[header]

                page_content[header] = content

            cache_data[title] = {'url': sub_url, 'content': page_content}

        with open(cache_file, 'w+') as f:
            f.write(json.dumps(cache_data))
        self.guide_tree = cache_data
        self._send_log(f"initialized SearchManager from '{base_url}'", 'info')
        return True

    # Generates a list of available options based on the current screen
    def filter_options(self, current_screen):
        from source.core.server.foundry import new_server_info
        from source.core.server import playit

        screen_list = self.options_tree['MainMenu']
        final_list = []

        if current_screen.startswith('ServerImport'):
            screen_list.extend(self.options_tree['ServerImport'])

        if current_screen.startswith('CreateServer'):
            for screen in self.options_tree['CreateServer']:
                if not (new_server_info['type'] == 'vanilla' and screen.id == 'ServerAddonScreen'):
                    if screen not in screen_list:
                        screen_list.append(screen)

        if server_manager.current_server:
            for screen in self.options_tree['Server']:
                if not (server_manager.current_server.type == 'vanilla' and screen.id == 'ServerAddonScreen'):
                    if screen not in screen_list:
                        screen_list.append(screen)


        # Iterate through available screens to create search objects
        for screen in screen_list:
            if screen.id == 'ServerManagerScreen':
                final_list.append(ScreenResult(screen.name, 'Configuration page', screen.id, screen.helper_keywords))
                for server, telepath_data in screen.options().items():
                    if telepath_data:
                        telepath = deepcopy(telepath_data)
                        telepath['name'] = server.rsplit('/', 1)[-1]
                        keywords = [telepath['host'], telepath['nickname'], 'telepath', 'remote', telepath['name']]
                        final_list.append(ServerResult(server, 'Telepath server', None, keywords, telepath=telepath))
                    else:
                        final_list.append(ServerResult(server, 'Installed server', None))

            elif (screen.id.startswith('Server') and 'Import' not in screen.id) and server_manager.current_server:
                keywords = list(screen.options.keys())
                keywords.extend(screen.helper_keywords)
                if current_screen != screen.id:
                    final_list.append(ScreenResult(screen.name, f'Configuration page ({server_manager.current_server.name})', screen.id, keywords))
                for setting, value in screen.options.items():

                    # Ignore results for running server
                    if server_manager.current_server.running and setting.lower() in ('launch server', 'update this server', "change 'server.jar'", 'rename this server', 'change world file', 'delete this server'):
                        continue
                    elif not server_manager.current_server.running and setting.lower() in ('restart server', 'stop server'):
                        continue

                    # Change results for proxy installation
                    if setting.lower() == 'enable proxy (playit)' and not playit.manager._check_agent():
                        continue
                    if setting.lower() == 'install proxy (playit)' and playit.manager._check_agent():
                        continue

                    # If server is up-to-date, hide update prompt
                    if setting.lower() == 'update this server' and not server_manager.current_server.update_string:
                        continue

                    final_list.append(SettingResult(setting, f'Action in {screen.name} ({server_manager.current_server.name})', value if value else screen.id, keywords))

            else:
                keywords = list(screen.options.keys())
                keywords.extend(screen.helper_keywords)
                final_list.append(ScreenResult(screen.name, 'Configuration page', screen.id, keywords))
                for setting, value in screen.options.items():

                    if setting.lower() == 'update buddyservers' and app_latest:
                        continue

                    final_list.append(SettingResult(setting, f'Action in {screen.name}', value if value else screen.id, keywords))


        # Return a list of all created screens, settings, and guides
        return final_list

    # Generate a list of weighted results from a search
    def execute_search(self, current_screen, query):
        self._send_log(f"searching for '{query}'...")

        match_list = {
            'guide': SearchObject(),
            'setting': [],
            'screen': [],
            'server': []
        }

        # Cleanup strings
        def clean_str(string):
            return string.strip().lower().replace('-', '')

        # Removes common words to improve search results
        def remove_common_words(string):
            common_words = ['the', 'be', 'to', 'of', 'and', 'a', 'in', 'that', 'have', 'I', 'it', 'for', 'not',
                            'on', 'with', 'he', 'as', 'you', 'do', 'at', 'this', 'but', 'his', 'by', 'from', 'they',
                            'we', 'say', 'her', 'she', 'or', 'an', 'will', 'my', 'one', 'all', 'would', 'there',
                            'their', 'what', 'so', 'up', 'out', 'if', 'about', 'who', 'get', 'which', 'go', 'me',
                            'when', 'make', 'can', 'like', 'time', 'no', 'just', 'him', 'know', 'take', 'people',
                            'into', 'year', 'your', 'good', 'some', 'could', 'them', 'see', 'other', 'than', 'then',
                            'now', 'look', 'only', 'come', 'its', 'over', 'think', 'also', 'back', 'after', 'two',
                            'how', 'our', 'work', 'first', 'well', 'way', 'even', 'new', 'want', 'because', 'any',
                            'these', 'give', 'day', 'most', 'us', 'is']

            final_words = []

            for w in string.split(' '):
                if w.lower().strip() not in common_words:
                    final_words.append(w)

            return ' '.join(final_words)

        # Manual query overrides for improved results
        def check_overrides(s):
            def check_word(w):
                return len(re.findall(fr'\b{w}\b', s)) > 0

            if (check_word('automcs') or check_word('this')) and 'what' in query.lower():
                return 'getting started'

            elif (check_word('automcs') or check_word(
                'this')) and 'addon' not in query.lower() and 'script' not in query.lower() and (
                check_word('download') or check_word('use') or check_word('install') or check_word('get')):
                return 'installation'

            elif (check_word('level') or check_word('world')) and (
                'back' not in query.lower() and 'up' not in query.lower()):
                return 'change the world'

            elif check_word('ram') or check_word('memory'):
                return 'allocate memory'

            elif check_word('ide'):
                return 'amscript ide'

            elif 'modding' in query.lower():
                return 'installing addons'

            elif check_word('distribution'):
                return 'server type'

            elif (check_word('use') or check_word('controls') or check_word('help') or check_word('manager')) and (
                check_word('acl') or 'access control' in query.lower()):
                return 'what are rules'

            elif (check_word('make') or check_word('create')) and check_word('server'):
                return 'create a server'

            elif check_word('amscript') and 'what is' in query.lower():
                return 'amscript'

            elif 'port forward' in query.lower() or check_word(
                'nat') or 'address translation' in query.lower() or check_word('tcp') or check_word(
                'udp') or 'port trigger' in query.lower():
                return 'wan config'

            elif check_word('port') or check_word('ip'):
                return 'lan config'

            elif check_word('amscript') and (
                check_word('download') or check_word('use') or check_word('install') or check_word('get')):
                return 'amscript getting started'

            else: return s


        # Find matching objects
        options_list = self.filter_options(current_screen)
        if options_list:
            o_query = query

            # First check for a title match
            query = clean_str(query)

            replacements = [
                ('?', ''), ('$', ''), (',', ''),
                ('help', ''), ('guide', ''),
                ('mod', 'addon'), ('plugin', 'addon'),
                ('folder', 'directory'), ('path', 'directory'),
                ('addonpack', 'modpack')
            ]

            for (s, r) in replacements:
                if s == 'path' and 'tele' in query: continue
                query = query.replace(s, r)

            query = check_overrides(query)

            for obj in options_list:
                title = obj.title
                simple_query = remove_common_words(query)
                if simple_query in clean_str(obj.title):
                    obj.score = 100
                    if obj not in match_list[obj.type]:
                        match_list[obj.type].append(obj)

            # If no match was found, search every content header
            else:
                for obj in options_list:
                    title = clean_str(obj.title)
                    obj.score = 0

                    if query == title:
                        obj.score = 100

                    else:
                        # Initial score based on title match
                        obj.score = similarity(query, title) * 10

                        # Increase score comparing word by word
                        for w1 in title.split(' '):
                            for w2 in query.split(' '):
                                obj.score += ((similarity(w1, w2) * len(w2)) * 2)

                        # Finally, increase score by pre-existing keyword matches
                        for keyword in obj.keywords:
                            if clean_str(keyword) in query:
                                obj.score += 20

                        # Modify values based on object type
                        if obj.type in ['server'] and current_screen == 'ServerManagerScreen':
                            obj.score *= 2
                        elif obj.type in ['server'] and (current_screen.startswith('Server') or current_screen.startswith('CreateServer')):
                            obj.score /= 1.5

                    list_type = obj.type
                    if obj not in match_list[list_type]:
                        match_list[list_type].append(obj)


        # Search through every guide to return relevant information from a query
        if app_online and self.guide_tree:
            o_query = query

            # First check for a title match
            query = clean_str(query)

            replacements = [
                ('?', ''), ('$', ''), (',', ''),
                ('help', ''), ('guide', ''),
                ('mod', 'addon'), ('plugin', 'addon'),
                ('folder', 'directory'), ('path', 'directory'),
                ('addonpack', 'modpack')
            ]

            for (s, r) in replacements:
                if s == 'path' and 'tele' in query: continue
                query = query.replace(s, r)

            query = check_overrides(query)

            for title in self.guide_tree.keys():
                simple_query = remove_common_words(query)
                if simple_query in clean_str(title):
                    match_list['guide'] = GuideResult(
                        f'{title} - Overview',
                        'View guide from Wiki',
                        self.guide_tree[title]['url'],
                        score = 100
                    )

            # If no match was found, search every content header
            else:
                for page_title, data in self.guide_tree.items():
                    url = data['url']
                    content = data['content']

                    o_page_title = page_title
                    page_title = clean_str(page_title)

                    # Ignore pages based on query
                    def check_word_in_title(w1, w2=None, invert=False):
                        if not w2:
                            w2 = w1
                        if invert:
                            return w1 in query and w2 not in page_title
                        else:
                            return w1 not in query and w2 in page_title

                    if check_word_in_title('addon') or check_word_in_title('backup') or check_word_in_title('amscript'):
                        continue

                    if check_word_in_title('addon', invert=True) or check_word_in_title('backup', invert=True) or check_word_in_title('amscript', invert=True):
                        continue

                    for title, paragraph in content.items():
                        o_paragraph = paragraph
                        o_title = title
                        title = clean_str(title)
                        paragraph = clean_str(paragraph)

                        # If title matches query, give it a high score
                        if query == title:
                            similarity_score = 100
                        else:
                            # Calculate the similarity score
                            similarity_score = round(similarity(paragraph, query)) + similarity(title, query)

                            # If words from search are in the paragraph, increase score
                            for word in remove_common_words(query).split():
                                if len(word) > 2:
                                    similarity_score += (len(re.findall(fr'\b{word}\b', paragraph)) / 10)
                                    similarity_score += (len(re.findall(fr'\b{word}\b', title)) / 10)

                        # print(similarity_score)
                        if similarity_score > match_list['guide'].score:
                            if 'https://' in o_title.lower():
                                continue
                            match_list['guide'] = GuideResult(
                                f'{o_page_title} - {o_title.title()}',
                                'View guide from Wiki',
                                url + '#' + o_title.lower().replace(' ', '-'),
                                score = similarity_score
                            )

            if 'guide' in o_query.lower() or 'help' in o_query.lower():
                match_list['guide'].score = 1000

        match_list['setting'] = tuple(sorted(match_list['setting'], key=lambda x: x.score, reverse=True))
        match_list['screen'] = tuple(sorted(match_list['screen'], key=lambda x: x.score, reverse=True))
        match_list['server'] = tuple(sorted(match_list['server'], key=lambda x: x.score, reverse=True))
        self._send_log(f"results for '{query}':\n{match_list}")

        return match_list

# Global search manager
search_manager: SearchManager = None


# Base search result
class SearchObject():
    def __init__(self):
        self.type = 'undefined'
        self.score = 0

    def __repr__(self):
        title = getattr(self, 'title', None)
        return f'<{self.__class__.__name__} "{title}">'

# Search result that matches a setting
class SettingResult(SearchObject):
    def __init__(self, title, subtitle, target, keywords=[], score=0):
        super().__init__()
        self.type = 'setting'
        self.icon = os.path.join(paths.ui_assets, 'icons', 'play-circle-sharp.png')
        self.color = (0.7, 0.7, 1, 1)
        self.title = title
        self.subtitle = subtitle
        self.target = target
        self.keywords = keywords
        self.score = score

# Search result that matches an online guide
class GuideResult(SearchObject):
    def __init__(self, title, subtitle, target, keywords=[], score=0):
        super().__init__()
        self.type = 'guide'
        self.icon = os.path.join(paths.ui_assets, 'icons', 'newspaper.png')
        self.color = (0.6, 1, 0.75, 1)
        self.title = title
        self.subtitle = subtitle
        self.target = target
        self.keywords = keywords
        self.score = score

# Search result that matches an installed server
class ServerResult(SearchObject):
    def __init__(self, title, subtitle, target, keywords=[], score=0, telepath=None):
        super().__init__()
        self._telepath_data = telepath
        self.type = 'server'
        self.icon = os.path.join(paths.ui_assets, 'icons', 'sm', 'terminal.png')
        self.color = (1, 0.598, 0.9, 1)

        if self._telepath_data:
            self.title = f'[color=#9383A2]{self._telepath_data["display-name"]}/[/color]{self._telepath_data["name"]}'
        else:
            self.title = title
        self.subtitle = subtitle
        self.target = target
        self.keywords = keywords
        self.score = score

# Search result that matches a configuration page
class ScreenResult(SearchObject):
    def __init__(self, title, subtitle, target, keywords=[], score=0):
        super().__init__()
        self.type = 'screen'
        self.icon = os.path.join(paths.ui_assets, 'icons', 'exit-sharp.png')
        self.color = (0.639, 1, 1, 1)
        self.title = title
        self.subtitle = subtitle
        self.target = target
        self.keywords = keywords
        self.score = score
